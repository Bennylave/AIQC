{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "organic-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/layne/Desktop/aiqc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foster-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiqc\n",
    "from aiqc import datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nuclear-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiqc import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hybrid-moore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Success - deleted database file at path:\n",
      "/Users/layne/Library/Application Support/aiqc/aiqc.sqlite3\n",
      "\n",
      "\n",
      "=> Success - created database file at path:\n",
      "/Users/layne/Library/Application Support/aiqc/aiqc.sqlite3\n",
      "\n",
      "\n",
      "💾  Success - created all database tables.  💾\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aiqc.destroy_db(confirm=True, rebuild=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-disaster",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "assigned-league",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮:   0%|                                                  | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "['a',\n",
      " 'b',\n",
      " 'c',\n",
      " 'd',\n",
      " 'e',\n",
      " 'f',\n",
      " 'g',\n",
      " 'h',\n",
      " 'i',\n",
      " 'j',\n",
      " 'k',\n",
      " 'l',\n",
      " 'm',\n",
      " 'n',\n",
      " 'o',\n",
      " 'p',\n",
      " 'q',\n",
      " 'r',\n",
      " 's',\n",
      " 't',\n",
      " 'u',\n",
      " 'v',\n",
      " 'w',\n",
      " 'x',\n",
      " 'y',\n",
      " 'z',\n",
      " 'aa',\n",
      " 'ab',\n",
      " 'ac',\n",
      " 'ad',\n",
      " 'ae',\n",
      " 'af',\n",
      " 'ag',\n",
      " 'ah',\n",
      " 'ai',\n",
      " 'aj',\n",
      " 'ak',\n",
      " 'al',\n",
      " 'am',\n",
      " 'an',\n",
      " 'ao',\n",
      " 'ap',\n",
      " 'aq',\n",
      " 'ar',\n",
      " 'as',\n",
      " 'at',\n",
      " 'au',\n",
      " 'av',\n",
      " 'aw',\n",
      " 'ax',\n",
      " 'ay',\n",
      " 'az',\n",
      " 'ba',\n",
      " 'bb',\n",
      " 'bc',\n",
      " 'bd',\n",
      " 'be',\n",
      " 'bf',\n",
      " 'bg',\n",
      " 'bh']\n",
      "\n",
      "=> Nice! Now all feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n",
      "\n",
      "Warning - `function_model_optimize` is not defined, so \n",
      "the optimizer must be defined within either `function_model_train` \n",
      "or `function_model_build`; otherwise training will fail.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|██████████████████████████████████████████| 4/4 [00:38<00:00,  9.56s/it]\n"
     ]
    }
   ],
   "source": [
    "b1 = tests.make_test_batch('binary')\n",
    "b1.run_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "black-value",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮:   0%|                                                  | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "['petal_width']\n",
      "\n",
      "=> The remaining column(s) and dtype(s) can be used in downstream Featurecoder(s):\n",
      "{'petal_length': 'float64', 'sepal_length': 'float64', 'sepal_width': 'float64'}\n",
      "\n",
      "\n",
      "___/ featurecoder_index: 1 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "['sepal_length', 'sepal_width', 'petal_length']\n",
      "\n",
      "=> Nice! Now all feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n",
      "\n",
      "Warning - `function_model_optimize` is not defined, so \n",
      "the optimizer must be defined within either `function_model_train` \n",
      "or `function_model_build`; otherwise training will fail.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|██████████████████████████████████████████| 8/8 [00:29<00:00,  3.70s/it]\n"
     ]
    }
   ],
   "source": [
    "b2 = tests.make_test_batch('multiclass')\n",
    "b2.run_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prescription-browser",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮:   0%|                                                  | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'ptratio', 'lstat']\n",
      "\n",
      "=> The remaining column(s) and dtype(s) can be used in downstream Featurecoder(s):\n",
      "{'chas': 'int64', 'rad': 'int64', 'tax': 'int64'}\n",
      "\n",
      "\n",
      "___/ featurecoder_index: 1 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "['chas', 'tax', 'rad']\n",
      "\n",
      "=> Nice! Now all feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮: 100%|██████████████████████████████████████████| 4/4 [00:31<00:00,  7.90s/it]\n"
     ]
    }
   ],
   "source": [
    "b3 = tests.make_test_batch('regression')\n",
    "b3.run_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opposite-blake",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖼️ Validating Images 🖼️: 100%|███████████████████████| 80/80 [00:13<00:00,  5.88it/s]\n",
      "🖼️ Ingesting Images 🖼️: 100%|████████████████████████| 80/80 [00:05<00:00, 15.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning - `function_model_optimize` is not defined, so \n",
      "the optimizer must be defined within either `function_model_train` \n",
      "or `function_model_build`; otherwise training will fail.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = tests.make_test_batch('image_binary', repeat_count=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-romantic",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮:  12%|█████▏                                   | 2/16 [00:58<06:46, 29.01s/it]"
     ]
    }
   ],
   "source": [
    "batch.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-rouge",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "active-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, PowerTransformer, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "confused-constitution",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___/ featurecoder_index: 0 \\_________\n",
      "\n",
      "=> The column(s) below matched your filter(s) and were ran through a test-encoding successfully.\n",
      "['a',\n",
      " 'b',\n",
      " 'c',\n",
      " 'd',\n",
      " 'e',\n",
      " 'f',\n",
      " 'g',\n",
      " 'h',\n",
      " 'i',\n",
      " 'j',\n",
      " 'k',\n",
      " 'l',\n",
      " 'm',\n",
      " 'n',\n",
      " 'o',\n",
      " 'p',\n",
      " 'q',\n",
      " 'r',\n",
      " 's',\n",
      " 't',\n",
      " 'u',\n",
      " 'v',\n",
      " 'w',\n",
      " 'x',\n",
      " 'y',\n",
      " 'z',\n",
      " 'aa',\n",
      " 'ab',\n",
      " 'ac',\n",
      " 'ad',\n",
      " 'ae',\n",
      " 'af',\n",
      " 'ag',\n",
      " 'ah',\n",
      " 'ai',\n",
      " 'aj',\n",
      " 'ak',\n",
      " 'al',\n",
      " 'am',\n",
      " 'an',\n",
      " 'ao',\n",
      " 'ap',\n",
      " 'aq',\n",
      " 'ar',\n",
      " 'as',\n",
      " 'at',\n",
      " 'au',\n",
      " 'av',\n",
      " 'aw',\n",
      " 'ax',\n",
      " 'ay',\n",
      " 'az',\n",
      " 'ba',\n",
      " 'bb',\n",
      " 'bc',\n",
      " 'bd',\n",
      " 'be',\n",
      " 'bf',\n",
      " 'bg',\n",
      " 'bh']\n",
      "\n",
      "=> Nice! Now all feature column(s) have encoder(s) associated with them.\n",
      "No more Featurecoders can be added to this Encoderset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = datum.get_path('sonar.csv')\n",
    "\n",
    "dataset = aiqc.Dataset.Tabular.from_path(\n",
    "    file_path = file_path\n",
    "    , source_file_format = 'csv'\n",
    "    , name = 'rocks n radio'\n",
    "    , dtype = None\n",
    ")\n",
    "\n",
    "label_column = 'object'\n",
    "label = dataset.make_label(columns=[label_column])\n",
    "\n",
    "featureset = dataset.make_featureset(exclude_columns=[label_column])\n",
    "\n",
    "splitset = featureset.make_splitset(\n",
    "    label_id = label.id\n",
    "    , size_test = 0.27\n",
    ")\n",
    "\n",
    "encoderset = splitset.make_encoderset()\n",
    "\n",
    "labelcoder = encoderset.make_labelcoder(\n",
    "    sklearn_preprocess = LabelBinarizer(sparse_output=False)\n",
    ")\n",
    "\n",
    "fc0 = encoderset.make_featurecoder(\n",
    "    sklearn_preprocess = PowerTransformer(method='yeo-johnson', copy=False)\n",
    "    , dtypes = ['float64']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-canada",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adjustable-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "neither-remove",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/layne/.pyenv/versions/3.8.7/envs/jupyterlab3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass copy=yeo-johnson as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "encoder_feat = StandardScaler('yeo-johnson', copy=False)\n",
    "encoder_lab = LabelBinarizer(sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "monetary-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_feat = splitset.to_numpy()['train']['features']\n",
    "data_train_lab = splitset.to_numpy()['train']['labels']\n",
    "\n",
    "data_test_feat = splitset.to_numpy()['test']['features']\n",
    "data_test_lab = splitset.to_numpy()['test']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "reverse-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_feat = encoder_feat.fit_transform(data_train_feat)\n",
    "data_train_lab = encoder_lab.fit_transform(data_train_lab)\n",
    "\n",
    "data_test_feat = encoder_feat.fit_transform(data_test_feat)\n",
    "data_test_lab = encoder_lab.fit_transform(data_test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "parental-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_train_feat = torch.FloatTensor(data_train_feat)\n",
    "tz_train_lab = torch.FloatTensor(data_train_lab)\n",
    "\n",
    "tz_test_feat = torch.FloatTensor(data_test_feat)\n",
    "tz_test_lab = torch.FloatTensor(data_test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "protective-exception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([151, 60])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz_train_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-munich",
   "metadata": {},
   "source": [
    "will this work in the functional API?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "compliant-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    nn.Linear(60, 24),\n",
    "    nn.BatchNorm1d(24,24),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.4),\n",
    "\n",
    "    nn.Linear(24, 1),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-frederick",
   "metadata": {},
   "source": [
    "forward is only defined in the functional API?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "collect-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adamax(\n",
    "    model.parameters(),\n",
    "    lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "juvenile-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like it needs to be instantiated first\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-drove",
   "metadata": {},
   "source": [
    "now we call them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aware-tennis",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "preds = model(tz_train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "described-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(preds, tz_train_lab)\n",
    "# outputs a single scalar (aka 0-dim tensor, torch.Size([]) ) for the whole epoch?\n",
    "# tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dated-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "# how does this relate to `with torch.no_grad()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "excellent-occasions",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "peripheral-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-simpson",
   "metadata": {},
   "source": [
    "^ what does this do? not related to breaking for loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-missile",
   "metadata": {},
   "source": [
    "i don't think there is a `compile`, the model and opt are just called separately "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-thread",
   "metadata": {},
   "source": [
    "looks like i'll have to define the loss_fn separately from the model and then call it in the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "subjective-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-replication",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "it seems like batch_size is handled by the dataloader. because the dataloader is iterated over in most `forward` functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-shift",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "\"TypeError: linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-knock",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "look into `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-queue",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-planning",
   "metadata": {
    "tags": []
   },
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-living",
   "metadata": {
    "tags": []
   },
   "source": [
    "state dict\n",
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "indian-prairie",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.0967,  0.0656,  0.0295,  ...,  0.0214, -0.0767, -0.0084],\n",
       "                      [ 0.0903,  0.0663,  0.0691,  ..., -0.0805,  0.0507,  0.0972],\n",
       "                      [-0.0472, -0.0838,  0.0054,  ...,  0.0148, -0.0732, -0.0926],\n",
       "                      ...,\n",
       "                      [-0.0904, -0.0823, -0.0513,  ...,  0.0063,  0.0431,  0.0384],\n",
       "                      [ 0.0733,  0.0369, -0.0539,  ...,  0.0011, -0.0474, -0.0705],\n",
       "                      [ 0.0365,  0.0562, -0.0443,  ..., -0.1169,  0.0324,  0.0425]])),\n",
       "             ('0.bias',\n",
       "              tensor([ 0.1104, -0.0514,  0.0278,  0.0341, -0.0081, -0.0594, -0.0086,  0.1202,\n",
       "                       0.0902, -0.0891,  0.0299,  0.0080,  0.0718, -0.0367, -0.0250, -0.0038,\n",
       "                      -0.0722, -0.0783,  0.0195,  0.1138, -0.0545, -0.0376, -0.0097,  0.0385])),\n",
       "             ('1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1.])),\n",
       "             ('1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('1.running_mean',\n",
       "              tensor([ 0.0110, -0.0051,  0.0028,  0.0034, -0.0008, -0.0059, -0.0009,  0.0120,\n",
       "                       0.0090, -0.0089,  0.0030,  0.0008,  0.0072, -0.0037, -0.0025, -0.0004,\n",
       "                      -0.0072, -0.0078,  0.0020,  0.0114, -0.0055, -0.0038, -0.0010,  0.0039])),\n",
       "             ('1.running_var',\n",
       "              tensor([0.9196, 0.9280, 0.9389, 0.9297, 0.9431, 0.9435, 0.9366, 0.9363, 0.9301,\n",
       "                      0.9263, 0.9250, 0.9245, 0.9309, 0.9348, 0.9390, 0.9291, 0.9652, 0.9378,\n",
       "                      0.9538, 0.9538, 0.9315, 0.9249, 0.9148, 0.9298])),\n",
       "             ('1.num_batches_tracked', tensor(1)),\n",
       "             ('4.weight',\n",
       "              tensor([[ 0.0568,  0.1866, -0.0251, -0.0991,  0.0950,  0.0089, -0.1884,  0.0091,\n",
       "                       -0.0938,  0.1341,  0.1078,  0.0831, -0.0859,  0.0497, -0.0254, -0.0384,\n",
       "                       -0.0859, -0.0146, -0.1850,  0.0192, -0.1796,  0.0704, -0.1119,  0.0294]])),\n",
       "             ('4.bias', tensor([-0.0720]))])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "french-element",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {},\n",
       " 'param_groups': [{'lr': 0.01,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'params': [0, 1, 2, 3, 4, 5]}]}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "alert-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "considered-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_blob = io.BytesIO()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-partnership",
   "metadata": {},
   "source": [
    "how to save optimizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "spread-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict()\n",
    "    },\n",
    "    model_blob\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "flexible-brick",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_blob = model_blob.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "polished-event",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_blob = io.BytesIO(model_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "steady-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(model_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "amateur-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = model.load_state_dict(\n",
    "    checkpoint['model_state_dict']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "present-going",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-techno",
   "metadata": {
    "tags": []
   },
   "source": [
    "how to get history?... skip it for pytorch for now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "industrial-house",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.container.Sequential"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "suburban-watch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=60, out_features=24, bias=True)\n",
       "  (1): BatchNorm1d(24, eps=24, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.4, inplace=False)\n",
       "  (4): Linear(in_features=24, out_features=1, bias=True)\n",
       "  (5): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fundamental-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "faced-screening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "electoral-liverpool",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-fusion",
   "metadata": {},
   "source": [
    "`load_state_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-accessory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
