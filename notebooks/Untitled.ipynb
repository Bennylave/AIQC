{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/layne/Desktop/aiqc'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/Users/layne/Desktop/aiqc')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import aiqc\n",
    "from aiqc import examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Success - deleted database file at path:\n",
      "/Users/layne/Library/Application Support/aiqc/aiqc.sqlite3\n",
      "\n",
      "\n",
      "=> Success - created database file for machine learning metrics at path:\n",
      "/Users/layne/Library/Application Support/aiqc/aiqc.sqlite3\n",
      "\n",
      "\n",
      "=> Success - created the following tables within database:\n",
      "['algorithm', 'batch', 'dataset', 'encoderset', 'featureset', 'file', 'fold', 'foldset', 'hyperparamcombo', 'hyperparamset', 'image', 'job', 'jobset', 'label', 'labelcoder', 'result', 'splitset', 'tabular']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from importlib import reload\n",
    "# aiqc.delete_db(True)\n",
    "# reload(aiqc)\n",
    "# aiqc.create_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Str Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "kingdom_lst = [\n",
    "    'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', \n",
    "    'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', \n",
    "    'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Int OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_lst = [\n",
    "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_lst = [\n",
    "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Int Pre-Ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_lst = [\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "moon_day_lst = [\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
    "    1, 2, 3, 4\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Str Pre-Ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_lst = [\n",
    "    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'twenty-one', 'twenty-two', 'twenty-three', 'twenty-four',\n",
    "    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'twenty-one', 'twenty-two', 'twenty-three', 'twenty-four',\n",
    "    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'twenty-one', 'twenty-two', 'twenty-three', 'twenty-four',\n",
    "    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'twenty-one', 'twenty-two', 'twenty-three', 'twenty-four',\n",
    "    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'twenty-one', 'twenty-two', 'twenty-three', 'twenty-four',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_lst = [\n",
    "    'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday','sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday','sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday','sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_lst = [1.5*n for i,n in enumerate(range(120))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiance_lst = [(-1)*2.0*0.05*(n+1) for i,n in enumerate(range(120))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "doom_factor_lst = [(100000.5 - 69.13*3*n) for i,n in enumerate(range(120))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = [doom_factor_lst, radiance_lst, temp_lst, weekday_lst, hour_lst, moon_day_lst, month_lst, color_lst, shape_lst, kingdom_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in list_of_lists:\n",
    "    if len(l) != 120:\n",
    "        print(f\"{l}: length {len(l)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [np.array(l) for l in list_of_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays_tup = tuple(arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_of_arrays = np.column_stack(arrays_tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['doom_float64', 'radiance_float32', 'temperature_float', 'weekday_object', 'hour_object', 'moonday_int64', 'month_int32', 'color_uint8', 'shape_int', 'kingdom_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(array_of_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dict = {}\n",
    "for i, n in enumerate(column_names):\n",
    "    column_dict[i] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns=column_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doom_float64          float64\n",
       "radiance_float32      float32\n",
       "temperature_float     float64\n",
       "weekday_object         object\n",
       "hour_object            string\n",
       "moonday_int64           int64\n",
       "month_int32             int32\n",
       "color_uint8             uint8\n",
       "shape_int               int64\n",
       "kingdom_category     category\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"/Users/Layne/Desktop/aiqc/aiqc/data/dtype_testing.parquet\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/Users/Layne/Desktop/aiqc/aiqc/data/dtype_testing.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doom_float64          float64\n",
       "radiance_float32      float32\n",
       "temperature_float     float64\n",
       "weekday_object         object\n",
       "hour_object            string\n",
       "moonday_int64           int64\n",
       "month_int32             int32\n",
       "color_uint8             uint8\n",
       "shape_int               int64\n",
       "kingdom_category     category\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'doom_float64': 'float64'\n",
    "    , 'radiance_float32': 'float32'\n",
    "    , 'temperature_float': 'float'\n",
    "    , 'moonday_int64': 'int64'\n",
    "    , 'month_int32': 'int32'\n",
    "    , 'color_uint8': 'uint8'\n",
    "    , 'shape_int': 'int'\n",
    "    , 'weekday_object': 'object'\n",
    "    , 'hour_object': 'string'\n",
    "    , 'kingdom_category': 'category'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = aiqc.Dataset.Tabular.from_pandas(df, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dataset.make_label(columns=['kingdom_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset = dataset.make_featureset(exclude_columns=['kingdom_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = featureset.make_splitset(\n",
    "    label_id=label.id\n",
    "    , size_test = 0.22\n",
    "    , size_validation = 0.12 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = aiqc.Splitset.get_by_id(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderset = splitset.make_encoderset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelcoder = encoderset.make_labelcoder(\n",
    "    sklearn_preprocess = OneHotEncoder()\n",
    "    , only_fit_train = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = splitset.to_pandas(splits=['train', 'validation', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation', 'test'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kingdom_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>hylian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>hylian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>hylian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    kingdom_category\n",
       "26            kokiri\n",
       "24            kokiri\n",
       "102           gerudo\n",
       "69            hylian\n",
       "30            kokiri\n",
       "..               ...\n",
       "10            kokiri\n",
       "62            hylian\n",
       "18            kokiri\n",
       "114           gerudo\n",
       "41            hylian\n",
       "\n",
       "[78 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['train']['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    featureset_encoders:list\n",
    "    label_encoder:object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.label_encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.featureset_encoders = [\n",
    "    {\n",
    "       \"all_columns\": False #default True\n",
    "        , \"dtypes_include\": ['float64', 'float32']\n",
    "        , \"dtypes_exclude\": None\n",
    "        , \"columns_include\": ['temperature_float']\n",
    "        , \"columns_exclude\": None\n",
    "        , \"sklearn_preprocess\": OrdinalEncoder()\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo']], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitset.label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "encoder.fit_transform(splitset.to_numpy(splits=['train'])['train']['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, if the dtype filters exist, apply them.\n",
    "  - If both None, then pass `df.select_dtypes(include=set(df.columns.to_list())))`\n",
    "- Then get a list of remaining columns.\n",
    "- Then include/exclude columns from that list.\n",
    "- The remaining columns will be encoded by the encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doom_float64</th>\n",
       "      <th>radiance_float32</th>\n",
       "      <th>temperature_float</th>\n",
       "      <th>weekday_object</th>\n",
       "      <th>hour_object</th>\n",
       "      <th>moonday_int64</th>\n",
       "      <th>month_int32</th>\n",
       "      <th>color_uint8</th>\n",
       "      <th>shape_int</th>\n",
       "      <th>kingdom_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000.50</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sunday</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99793.11</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>monday</td>\n",
       "      <td>two</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99585.72</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>three</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99378.33</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>four</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99170.94</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>thursday</td>\n",
       "      <td>five</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>76150.65</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>172.5</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>twenty</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>75943.26</td>\n",
       "      <td>-11.7</td>\n",
       "      <td>174.0</td>\n",
       "      <td>thursday</td>\n",
       "      <td>twenty-one</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>75735.87</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>175.5</td>\n",
       "      <td>friday</td>\n",
       "      <td>twenty-two</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>75528.48</td>\n",
       "      <td>-11.9</td>\n",
       "      <td>177.0</td>\n",
       "      <td>saturday</td>\n",
       "      <td>twenty-three</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>75321.09</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>178.5</td>\n",
       "      <td>sunday</td>\n",
       "      <td>twenty-four</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doom_float64  radiance_float32  temperature_float weekday_object  \\\n",
       "0       100000.50              -0.1                0.0         sunday   \n",
       "1        99793.11              -0.2                1.5         monday   \n",
       "2        99585.72              -0.3                3.0        tuesday   \n",
       "3        99378.33              -0.4                4.5      wednesday   \n",
       "4        99170.94              -0.5                6.0       thursday   \n",
       "..            ...               ...                ...            ...   \n",
       "115      76150.65             -11.6              172.5      wednesday   \n",
       "116      75943.26             -11.7              174.0       thursday   \n",
       "117      75735.87             -11.8              175.5         friday   \n",
       "118      75528.48             -11.9              177.0       saturday   \n",
       "119      75321.09             -12.0              178.5         sunday   \n",
       "\n",
       "      hour_object  moonday_int64  month_int32  color_uint8  shape_int  \\\n",
       "0             one              1            1            0          0   \n",
       "1             two              2            2            0          0   \n",
       "2           three              3            3            0          0   \n",
       "3            four              4            4            0          0   \n",
       "4            five              5            5            0          0   \n",
       "..            ...            ...          ...          ...        ...   \n",
       "115        twenty             29            8            3          2   \n",
       "116    twenty-one              1            9            3          2   \n",
       "117    twenty-two              2           10            3          2   \n",
       "118  twenty-three              3           11            3          2   \n",
       "119   twenty-four              4           12            3          2   \n",
       "\n",
       "    kingdom_category  \n",
       "0             kokiri  \n",
       "1             kokiri  \n",
       "2             kokiri  \n",
       "3             kokiri  \n",
       "4             kokiri  \n",
       "..               ...  \n",
       "115           gerudo  \n",
       "116           gerudo  \n",
       "117           gerudo  \n",
       "118           gerudo  \n",
       "119           gerudo  \n",
       "\n",
       "[120 rows x 10 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dtypes_include': ['float64', 'float32'],\n",
       "  'dtypes_exclude': None,\n",
       "  'columns_include': None,\n",
       "  'columns_exclude': ['temperature_float'],\n",
       "  'encoder': OrdinalEncoder()}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filters_included_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    (preproc.featureset_encoders[0]['dtypes_include'] is None)\n",
    "    and\n",
    "    (preproc.featureset_encoders[0]['dtypes_exclude'] is None)\n",
    "):\n",
    "    # If no dtype filters, just take all columns and move to next step.\n",
    "    subset_columns = df.columns.to_list()\n",
    "else:    \n",
    "    subset_columns = df.select_dtypes(\n",
    "        include = preproc.featureset_encoders[0]['dtypes_include']\n",
    "        , exclude = preproc.featureset_encoders[0]['dtypes_exclude']\n",
    "    ).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doom_float64', 'radiance_float32', 'temperature_float']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creation validation:\n",
    "\n",
    "`.from_splitset`\n",
    "\n",
    "splitset must be supervised to add a EncoderLabel\n",
    "check len of relations on run.\n",
    "\n",
    "== for each encoder ==\n",
    "- Check `len(preprocess.encoderfeaturesets)` if > 1 then `all_columns` cannot be True.\n",
    "- if `all_remaining_columns==True`... you cannot have more than 1 encoder. \n",
    "- if `all_remaining_columns==True`... then `dtypes_include` and `dtypes_exclude` cannot be set.\n",
    "- Error if `sklearn_preprocess` is None.\n",
    "- Error if `all_remaining_columns==False` and the include/excludes are all None.\n",
    "\n",
    "== dtype ==\n",
    "- can't have same the dtype in both include and exclude.\n",
    "- if both None: pass #be explicit about it.\n",
    "- validate that dtypes used are present in remaining featureset df. # this would happen in try?\n",
    "\n",
    "\n",
    "== colnames ==\n",
    "if both None: pass #be explicit about it.\n",
    "if (not None): \n",
    "- #check if list empty. if (not mylist): raise ValueError \n",
    "- can't have same col_name in include and exclude.\n",
    "- check that column name is present in remaining featureset df. # this would happen in try?\n",
    "\n",
    "\n",
    "== try ===\n",
    "- don't run if len 0\n",
    "- run the entire chain of Preprocessset in order.\n",
    "- try: except: else: it runs clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that way, when it comes time to run it, it can just be ran... because we know it will work. much better for UX too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with this and keep pruning it.\n",
    "# can continually check dtypes and cols of it.\n",
    "\n",
    "#remaining_df = df\n",
    "#remaining_cols = cols?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not subset_columns):\n",
    "    raise ValueError(\"\\nYikes - After applying `dtypes_include` and `dtypes exclude`, there are no columns left to work with.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (preproc.featureset_encoders[0]['columns_include'] is not None):\n",
    "    # Move to creation.\n",
    "    #if (preproc.featureset_encoders[0]['columns_exclude'] is not None):\n",
    "    #    raise ValueError(\"\\nYikes - Either `include_columns` or `exclude_columns` can be set, but not both.\\n\")    \n",
    "    include = preproc.featureset_encoders[0]['columns_include']\n",
    "    # Move to creation.\n",
    "    #if (not include):\n",
    "    #    raise ValueError(\"\\nYikes - Inclusion/ exclusion lists can be None, but cannot be empty e.g. `[]`.\\n\")\n",
    "    \n",
    "    # `in` must be an exact match when used at the list level.\n",
    "    # Partial matched like `\"saw\" in \"sawdust\"` don't trigger it.\n",
    "    subset_columns = [c for c in subset_columns if c in include]\n",
    "\n",
    "elif (preproc.featureset_encoders[0]['columns_exclude'] is not None):\n",
    "    # Move to creation.\n",
    "    #if (preproc.featureset_encoders[0]['columns_include'] is not None):\n",
    "    #    raise ValueError(\"\\nYikes - Either `include_columns` or `exclude_columns` can be set, but not both.\\n\")\n",
    "    exclude = preproc.featureset_encoders[0]['columns_exclude']\n",
    "    # Move to creation.\n",
    "    #if (not exclude):\n",
    "    #    raise ValueError(\"\\nYikes - Inclusion/ exclusion lists can be None, but cannot be empty e.g. `[]`.\\n\") \n",
    "    subset_columns = [c for c in subset_columns if c not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not subset_columns):\n",
    "    raise ValueError(\"\\nYikes - After applying `columns_include` and `columns_exclude`, there are no columns left to work with.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check columns against macro list. \n",
    "error if they are found.\n",
    "otherwise add them to the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df...selected_columns...straight to numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add to list of numpys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then prune original df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run next filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after all filters, combine the numpys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_details = preproc.featureset_encoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_encoder = subset_details['encoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df.select_dtypes(subset_details['include'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = subset.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_encoded_arr = subset_encoder.fit_transform(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_details_2 = preproc.featureset_encoder[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_encoder_2 = subset_details_2['encoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_2 = df.select_dtypes(subset_details_2['include'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols_2 = subset_2.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_encoded_arr_2 = subset_encoder_2.fit_transform(subset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12052239, -0.73266327],\n",
       "       [-1.28055041, -0.6812386 ],\n",
       "       [ 1.16002802,  1.41390187]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_encoded_arr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_encoded_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12052239, -0.73266327],\n",
       "       [-1.28055041, -0.6812386 ],\n",
       "       [ 1.16002802,  1.41390187]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_encoded_arr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.12052239, -0.73266327],\n",
       "       [ 1.        , -1.28055041, -0.6812386 ],\n",
       "       [ 2.        ,  1.16002802,  1.41390187]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((subset_encoded_arr, subset_encoded_arr_2), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in subset_cols:\n",
    "    encoded_cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in subset_cols_2:\n",
    "    encoded_cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mode', 'size', 'height']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should do this as often as possible to reduce memory?\n",
    "df = df[df.columns.difference(encoded_cols, sort=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(encoded_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>larry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name\n",
       "0    bob\n",
       "1    jim\n",
       "2  larry"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "oher = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oher.fit(df[['name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = oher.transform(df[['name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 50 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((subset_encoded_arr, subset_encoded_arr_2), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<class 'scipy.sparse.csr.csr_matrix'>\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(type(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.toarray()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordiner = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalEncoder()"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordiner.fit(df[['price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = ordiner.transform(df[['price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.],\n",
       "       [27.],\n",
       "       [39.],\n",
       "       [38.],\n",
       "       [41.],\n",
       "       [36.],\n",
       "       [29.],\n",
       "       [35.],\n",
       "       [12.],\n",
       "       [17.]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
