{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/layne/Desktop/aiqc'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/Users/layne/Desktop/aiqc')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import aiqc\n",
    "from aiqc import examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Success - deleted database file at path:\n",
      "/Users/layne/Library/Application Support/aiqc/aiqc.sqlite3\n",
      "\n",
      "\n",
      "=> Success - created database file at path:\n",
      "/Users/layne/Library/Application Support/aiqc/aiqc.sqlite3\n",
      "\n",
      "\n",
      "=> Success - created the following tables within database:\n",
      "['algorithm', 'batch', 'dataset', 'encoderset', 'featurecoder', 'featureset', 'file', 'fold', 'foldset', 'hyperparamcombo', 'hyperparamset', 'image', 'job', 'jobset', 'label', 'labelcoder', 'result', 'splitset', 'tabular']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "aiqc.delete_db(True)\n",
    "reload(aiqc)\n",
    "aiqc.create_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = aiqc.Dataset.Tabular.from_path(\n",
    "    examples.get_demo_file_path('iris.tsv')\n",
    "    , source_file_format = 'tsv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    float64\n",
       "sepal_width     float64\n",
       "petal_length    float64\n",
       "petal_width     float64\n",
       "species           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas().head().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nYikes - You specified `columns` that do not exist in the Dataset.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-41871ad5a46f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kingdom_category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/aiqc/aiqc/__init__.py\u001b[0m in \u001b[0;36mmake_label\u001b[0;34m(id, columns)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mmake_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/aiqc/aiqc/__init__.py\u001b[0m in \u001b[0;36mfrom_dataset\u001b[0;34m(dataset_id, columns)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0mall_cols_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md_cols\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_cols_found\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nYikes - You specified `columns` that do not exist in the Dataset.\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;31m# Check for duplicates of this label that already exist.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \nYikes - You specified `columns` that do not exist in the Dataset.\n"
     ]
    }
   ],
   "source": [
    "label = dataset.make_label(columns=['kingdom_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset = dataset.make_featureset(exclude_columns=[\n",
    "    'kingdom_category', 'radiance_float32', 'temperature_float', 'doom_float64'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = featureset.make_splitset(\n",
    "    label_id=label.id\n",
    "    , size_test = 0.22\n",
    "    , size_validation = 0.12 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderset = splitset.make_encoderset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelcoder = encoderset.make_labelcoder(\n",
    "    sklearn_preprocess = OneHotEncoder(sparse=False)\n",
    "    , only_fit_train = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc = encoderset.make_featurecoder(\n",
    "# \tsklearn_preprocess = StandardScaler()\n",
    "# \t, only_fit_train = True\n",
    "# \t, include = True\n",
    "# \t, dtypes = ['float32']\n",
    "# \t, columns = None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc = encoderset.make_featurecoder(\n",
    "# \tsklearn_preprocess = OrdinalEncoder()\n",
    "# \t, only_fit_train = False\n",
    "# \t, include = True\n",
    "# \t, dtypes = None\n",
    "# \t, columns = ['hour_object', 'month_int32', 'moonday_int64', \"weekday_object\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc = encoderset.make_featurecoder(\n",
    "# \tsklearn_preprocess = OneHotEncoder(sparse=False)\n",
    "# \t, only_fit_train = False\n",
    "# \t, include = True\n",
    "# \t, dtypes = ['uint8', 'int64']\n",
    "# \t, columns = None\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featureset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_function_model_build(**hyperparameters):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(hyperparameters['neuron_count'], input_shape=(9,), activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(hyperparameters['neuron_count'], activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\topt = keras.optimizers.Adamax(hyperparameters['learning_rate'])\n",
    "\tmodel.compile(\n",
    "\t\tloss = 'categorical_crossentropy'\n",
    "\t\t, optimizer = opt\n",
    "\t\t, metrics = ['accuracy']\n",
    "\t)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_function_model_train(model, samples_train, samples_evaluate, **hyperparameters):\n",
    "\tmodel.fit(\n",
    "\t\tsamples_train[\"features\"]\n",
    "\t\t, samples_train[\"labels\"]\n",
    "\t\t, validation_data = (\n",
    "\t\t\tsamples_evaluate[\"features\"]\n",
    "\t\t\t, samples_evaluate[\"labels\"]\n",
    "\t\t)\n",
    "\t\t, verbose = 0\n",
    "\t\t, batch_size = hyperparameters['batch_size']\n",
    "\t\t, epochs = hyperparameters['epoch_count']\n",
    "\t\t, callbacks=[History()]\n",
    "\t)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = aiqc.Algorithm.make(\n",
    "    library = \"keras\"\n",
    "    , analysis_type = \"classification_multi\"\n",
    "    , function_model_build = multiclass_function_model_build\n",
    "    , function_model_train = multiclass_function_model_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"neuron_count\": [9, 12]\n",
    "    , \"epoch_count\": [30, 60]\n",
    "    , \"learning_rate\": [0.01]\n",
    "    , \"batch_size\": [3, 5]\n",
    "}\n",
    "\n",
    "hyperparamset = aiqc.Hyperparamset.from_algorithm(\n",
    "    algorithm_id = algorithm.id\n",
    "    , hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = aiqc.Batch.from_algorithm(\n",
    "    algorithm_id = algorithm.id\n",
    "    , splitset_id = splitset.id\n",
    "    , hyperparamset_id = hyperparamset.id\n",
    "    , foldset_id = None\n",
    "    , encoderset_id = encoderset.id\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
