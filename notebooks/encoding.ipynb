{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/layne/Desktop/aiqc'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/Users/layne/Desktop/aiqc')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import aiqc\n",
    "from aiqc import examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aiqc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9d23c6fd745f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maiqc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maiqc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maiqc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aiqc' is not defined"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "aiqc.delete_db(True)\n",
    "reload(aiqc)\n",
    "aiqc.create_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Str Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "kingdom_lst = [\n",
    "    'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', 'kokiri', \n",
    "    'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', 'hylian', \n",
    "    'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', 'gerudo', \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Int OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_lst = [\n",
    "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_lst = [\n",
    "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Int Pre-Ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_lst = [\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "moon_day_lst = [\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
    "    1, 2, 3, 4\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Str Pre-Ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_lst = [\n",
    "    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'twenty-one', 'twenty-two', 'twenty-three', 'twenty-four',\n",
    "    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'twenty-one', 'twenty-two', 'twenty-three', 'twenty-four',\n",
    "    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'twenty-one', 'twenty-two', 'twenty-three', 'twenty-four',\n",
    "    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'twenty-one', 'twenty-two', 'twenty-three', 'twenty-four',\n",
    "    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'twenty-one', 'twenty-two', 'twenty-three', 'twenty-four',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_lst = [\n",
    "    'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday','sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday','sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday','sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_lst = [1.5*n for i,n in enumerate(range(120))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiance_lst = [(-1)*2.0*0.05*(n+1) for i,n in enumerate(range(120))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "doom_factor_lst = [(100000.5 - 69.13*3*n) for i,n in enumerate(range(120))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = [doom_factor_lst, radiance_lst, temp_lst, weekday_lst, hour_lst, moon_day_lst, month_lst, color_lst, shape_lst, kingdom_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in list_of_lists:\n",
    "    if len(l) != 120:\n",
    "        print(f\"{l}: length {len(l)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [np.array(l) for l in list_of_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays_tup = tuple(arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_of_arrays = np.column_stack(arrays_tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['doom_float64', 'radiance_float32', 'temperature_float', 'weekday_object', 'hour_object', 'moonday_int64', 'month_int32', 'color_uint8', 'shape_int', 'kingdom_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(array_of_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dict = {}\n",
    "for i, n in enumerate(column_names):\n",
    "    column_dict[i] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns=column_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doom_float64          float64\n",
       "radiance_float32      float32\n",
       "temperature_float     float64\n",
       "weekday_object         object\n",
       "hour_object            string\n",
       "moonday_int64           int64\n",
       "month_int32             int32\n",
       "color_uint8             uint8\n",
       "shape_int               int64\n",
       "kingdom_category     category\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"/Users/Layne/Desktop/aiqc/aiqc/data/dtype_testing.parquet\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_path = examples.get_demo_file_path('iris.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = aiqc.Dataset.Tabular.from_path(iris_path, source_file_format='tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dataset.make_label(columns=['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset = dataset.make_featureset(exclude_columns=['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = featureset.make_splitset(\n",
    "    label_id=label.id\n",
    "    , size_test = 0.22\n",
    "    , size_validation = 0.12 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitset = aiqc.Splitset.get_by_id(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderset = splitset.make_encoderset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelcoder = encoderset.make_labelcoder(\n",
    "    sklearn_preprocess = OrdinalEncoder()\n",
    "    , only_fit_train = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitset.featureset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_function_model_build(**hyperparameters):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(hyperparameters['neuron_count'], input_shape=(4,), activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(hyperparameters['neuron_count'], activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\topt = keras.optimizers.Adamax(hyperparameters['learning_rate'])\n",
    "\tmodel.compile(\n",
    "\t\tloss = 'categorical_crossentropy'\n",
    "\t\t, optimizer = opt\n",
    "\t\t, metrics = ['accuracy']\n",
    "\t)\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def multiclass_function_model_train(model, samples_train, samples_evaluate, **hyperparameters):\n",
    "\tmodel.fit(\n",
    "\t\tsamples_train[\"features\"]\n",
    "\t\t, samples_train[\"labels\"]\n",
    "\t\t, validation_data = (\n",
    "\t\t\tsamples_evaluate[\"features\"]\n",
    "\t\t\t, samples_evaluate[\"labels\"]\n",
    "\t\t)\n",
    "\t\t, verbose = 0\n",
    "\t\t, batch_size = hyperparameters['batch_size']\n",
    "\t\t, epochs = hyperparameters['epoch_count']\n",
    "\t\t, callbacks=[History()]\n",
    "\t)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"neuron_count\": [9, 12]\n",
    "    , \"batch_size\": [3]\n",
    "    , \"learning_rate\": [0.03, 0.05]\n",
    "    , \"epoch_count\": [30, 60]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = aiqc.Algorithm.make(\n",
    "    library = \"keras\"\n",
    "    , analysis_type = \"classification_multi\"\n",
    "    , function_model_build = multiclass_function_model_build\n",
    "    , function_model_train = multiclass_function_model_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparamset = algorithm.make_hyperparamset(\n",
    "    hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = algorithm.make_batch(\n",
    "    splitset_id = splitset.id\n",
    "    , foldset_id = None\n",
    "    , hyperparamset_id = hyperparamset.id\n",
    "    , encoderset_id  = encoderset.id\n",
    "    , repeat_count = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'splitset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-991-6bafabb19275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msplitset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'splitset' is not defined"
     ]
    }
   ],
   "source": [
    "splitset.label.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔮 Training Models 🔮:   0%|                                                  | 0/8 [00:00<?, ?it/s]\n",
      "Process aiqc_batch_3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/layne/.pyenv/versions/3.7.6/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/layne/.pyenv/versions/3.7.6/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/layne/Desktop/aiqc/aiqc/__init__.py\", line 2663, in background_proc\n",
      "    job.run(verbose=verbose, repeat_index=repeat_index)\n",
      "  File \"/Users/layne/Desktop/aiqc/aiqc/__init__.py\", line 3102, in run\n",
      "    , **hyperparameters\n",
      "  File \"<ipython-input-40-4c559ec42ff1>\", line 28, in multiclass_function_model_train\n",
      "    , callbacks=[History()]\n",
      "  File \"/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1098, in fit\n",
      "    tmp_logs = train_function(iterator)\n",
      "  File \"/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 823, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 697, in _initialize\n",
      "    *args, **kwds))\n",
      "  File \"/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2855, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3213, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3075, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 600, in wrapped_fn\n",
      "    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 973, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n",
      "        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n",
      "        return self._call_for_each_replica(fn, args, kwargs)\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n",
      "        return fn(*args, **kwargs)\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:749 train_step\n",
      "        y, y_pred, sample_weight, regularization_losses=self.losses)\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:149 __call__\n",
      "        losses = ag_call(y_true, y_pred)\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:253 call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n",
      "        return target(*args, **kwargs)\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n",
      "        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n",
      "        return target(*args, **kwargs)\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n",
      "        target.shape.assert_is_compatible_with(output.shape)\n",
      "    /Users/layne/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n",
      "        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n",
      "\n",
      "    ValueError: Shapes (3, 1) and (3, 3) are incompatible\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch.run_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = splitset.to_pandas(splits=['train', 'validation', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation', 'test'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kingdom_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>hylian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>hylian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>hylian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    kingdom_category\n",
       "26            kokiri\n",
       "24            kokiri\n",
       "102           gerudo\n",
       "69            hylian\n",
       "30            kokiri\n",
       "..               ...\n",
       "10            kokiri\n",
       "62            hylian\n",
       "18            kokiri\n",
       "114           gerudo\n",
       "41            hylian\n",
       "\n",
       "[78 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['train']['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'doom_float64': 'float64'\n",
    "    , 'radiance_float32': 'float32'\n",
    "    , 'temperature_float': 'float'\n",
    "    , 'moonday_int64': 'int64'\n",
    "    , 'month_int32': 'int32'\n",
    "    , 'color_uint8': 'uint8'\n",
    "    , 'shape_int': 'int'\n",
    "    , 'weekday_object': 'object'\n",
    "    , 'hour_object': 'string'\n",
    "    , 'kingdom_category': 'category'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "funky_path = examples.get_demo_file_path('dtype_testing.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = aiqc.Dataset.Tabular.from_path(funky_path, source_file_format='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dataset.make_label(columns=['kingdom_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset = dataset.make_featureset(exclude_columns=['kingdom_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitset = featureset.make_splitset(\n",
    "    label_id = label.id\n",
    "    , size_test = 0.22\n",
    "    , size_validation = 0.12 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doom_float64          float64\n",
       "radiance_float32      float32\n",
       "temperature_float     float64\n",
       "weekday_object         object\n",
       "hour_object            string\n",
       "moonday_int64           int64\n",
       "month_int32             int32\n",
       "color_uint8             uint8\n",
       "shape_int               int64\n",
       "kingdom_category     category\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset_cols = featureset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_dtype = aiqc.Dataset.Tabular.get_main_tabular(dataset.id).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset_dtype = {}\n",
    "for c in featureset_cols:\n",
    "    for k,v in tabular_dtype.items():\n",
    "        if (c == k):\n",
    "            featureset_dtype[c] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doom_float64': 'float64',\n",
       " 'radiance_float32': 'float32',\n",
       " 'temperature_float': 'float64',\n",
       " 'weekday_object': 'object',\n",
       " 'hour_object': 'string',\n",
       " 'moonday_int64': 'int64',\n",
       " 'month_int32': 'int32',\n",
       " 'color_uint8': 'uint8',\n",
       " 'shape_int': 'int64'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureset_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include columns by dtype.\n",
    "match_count = 0\n",
    "for k,v in featureset_dtype.items():\n",
    "    if (v == dtype_name):\n",
    "        matching_columns.append(k)\n",
    "        match_count += 1\n",
    "if (match_count == 0):\n",
    "    raise ValueError(f\"\\nYikes - There are no columns remaining to include with the dtype of '{dtype_name}'.\\nRemove this criteria entry and try again.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sklearn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-01b63404e01b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sklearn' is not defined"
     ]
    }
   ],
   "source": [
    "sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude columns by dtype.\n",
    "match_count = 0\n",
    "for k,v in featureset_dtype.items():\n",
    "    if (v == dtype_name):\n",
    "        matching_columns.remove(k)\n",
    "        match_count += 1\n",
    "if (match_count == 0):\n",
    "    raise ValueError(f\"\\nYikes - There are no columns remaining to exclude with the dtype of '{dtype_name}'.\\nRemove this criteria entry and try again.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nYikes - There are no columns with the dtype of 'moat64'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-6377e8463149>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexcludeColsByDtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'moat64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-8a25b5c6f648>\u001b[0m in \u001b[0;36mexcludeColsByDtype\u001b[0;34m(tabular_dtype, dtype_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mmatching_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nYikes - There are no columns with the dtype of '{dtype_name}'.\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: \nYikes - There are no columns with the dtype of 'moat64'.\n"
     ]
    }
   ],
   "source": [
    "excludeColsByDtype(dtype, 'moat64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moonday_int64', 'shape_int']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Featurecoder:\n",
    "    encoderset_id:int\n",
    "    sklearn_preprocess:object\n",
    "    only_fit_train:bool = False\n",
    "    all_columns:list = True\n",
    "    dtypes_include:list = None\n",
    "    dtypes_exclude:list = None\n",
    "    columns_include:list = None\n",
    "    columns_exclude:list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurecoder = Featurecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurecoder.all_columns = False\n",
    "featurecoder.dtypes_include = ['float64', 'float32']\n",
    "featurecoder.dtypes_exclude = None\n",
    "featurecoder.columns_include = ['temperature_float']\n",
    "featurecoder.columns_exclude = None\n",
    "featurecoder.sklearn_preprocess = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['kokiri'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['hylian'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo'],\n",
       "       ['gerudo']], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitset.label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "encoder.fit_transform(splitset.to_numpy(splits=['train'])['train']['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, if the dtype filters exist, apply them.\n",
    "  - If both None, then pass `df.select_dtypes(include=set(df.columns.to_list())))`\n",
    "- Then get a list of remaining columns.\n",
    "- Then include/exclude columns from that list.\n",
    "- The remaining columns will be encoded by the encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doom_float64</th>\n",
       "      <th>radiance_float32</th>\n",
       "      <th>temperature_float</th>\n",
       "      <th>weekday_object</th>\n",
       "      <th>hour_object</th>\n",
       "      <th>moonday_int64</th>\n",
       "      <th>month_int32</th>\n",
       "      <th>color_uint8</th>\n",
       "      <th>shape_int</th>\n",
       "      <th>kingdom_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000.50</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sunday</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99793.11</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>monday</td>\n",
       "      <td>two</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99585.72</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>three</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99378.33</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>four</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99170.94</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>thursday</td>\n",
       "      <td>five</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>76150.65</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>172.5</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>twenty</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>75943.26</td>\n",
       "      <td>-11.7</td>\n",
       "      <td>174.0</td>\n",
       "      <td>thursday</td>\n",
       "      <td>twenty-one</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>75735.87</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>175.5</td>\n",
       "      <td>friday</td>\n",
       "      <td>twenty-two</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>75528.48</td>\n",
       "      <td>-11.9</td>\n",
       "      <td>177.0</td>\n",
       "      <td>saturday</td>\n",
       "      <td>twenty-three</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>75321.09</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>178.5</td>\n",
       "      <td>sunday</td>\n",
       "      <td>twenty-four</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>gerudo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doom_float64  radiance_float32  temperature_float weekday_object  \\\n",
       "0       100000.50              -0.1                0.0         sunday   \n",
       "1        99793.11              -0.2                1.5         monday   \n",
       "2        99585.72              -0.3                3.0        tuesday   \n",
       "3        99378.33              -0.4                4.5      wednesday   \n",
       "4        99170.94              -0.5                6.0       thursday   \n",
       "..            ...               ...                ...            ...   \n",
       "115      76150.65             -11.6              172.5      wednesday   \n",
       "116      75943.26             -11.7              174.0       thursday   \n",
       "117      75735.87             -11.8              175.5         friday   \n",
       "118      75528.48             -11.9              177.0       saturday   \n",
       "119      75321.09             -12.0              178.5         sunday   \n",
       "\n",
       "      hour_object  moonday_int64  month_int32  color_uint8  shape_int  \\\n",
       "0             one              1            1            0          0   \n",
       "1             two              2            2            0          0   \n",
       "2           three              3            3            0          0   \n",
       "3            four              4            4            0          0   \n",
       "4            five              5            5            0          0   \n",
       "..            ...            ...          ...          ...        ...   \n",
       "115        twenty             29            8            3          2   \n",
       "116    twenty-one              1            9            3          2   \n",
       "117    twenty-two              2           10            3          2   \n",
       "118  twenty-three              3           11            3          2   \n",
       "119   twenty-four              4           12            3          2   \n",
       "\n",
       "    kingdom_category  \n",
       "0             kokiri  \n",
       "1             kokiri  \n",
       "2             kokiri  \n",
       "3             kokiri  \n",
       "4             kokiri  \n",
       "..               ...  \n",
       "115           gerudo  \n",
       "116           gerudo  \n",
       "117           gerudo  \n",
       "118           gerudo  \n",
       "119           gerudo  \n",
       "\n",
       "[120 rows x 10 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dtypes_include': ['float64', 'float32'],\n",
       "  'dtypes_exclude': None,\n",
       "  'columns_include': None,\n",
       "  'columns_exclude': ['temperature_float'],\n",
       "  'encoder': OrdinalEncoder()}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filters_included_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    (preproc.featureset_encoders[0]['dtypes_include'] is None)\n",
    "    and\n",
    "    (preproc.featureset_encoders[0]['dtypes_exclude'] is None)\n",
    "):\n",
    "    # If no dtype filters, just take all columns and move to next step.\n",
    "    subset_columns = df.columns.to_list()\n",
    "else:    \n",
    "    subset_columns = df.select_dtypes(\n",
    "        include = preproc.featureset_encoders[0]['dtypes_include']\n",
    "        , exclude = preproc.featureset_encoders[0]['dtypes_exclude']\n",
    "    ).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doom_float64', 'radiance_float32', 'temperature_float']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creation validation:\n",
    "\n",
    "`.from_splitset`\n",
    "\n",
    "splitset must be supervised to add a EncoderLabel\n",
    "check len of relations on run.\n",
    "\n",
    "== chain ===\n",
    "- can't have an include column that previous ones had.\n",
    "- if previous encoder was 'all and no exclusion,' cannot add another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that way, when it comes time to run it, it can just be ran... because we know it will work. much better for UX too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with this and keep pruning it.\n",
    "# can continually check dtypes and cols of it.\n",
    "\n",
    "#remaining_df = df\n",
    "#remaining_cols = cols?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not subset_columns):\n",
    "    raise ValueError(\"\\nYikes - After applying `dtypes_include` and `dtypes exclude`, there are no columns left to work with.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (preproc.featureset_encoders[0]['columns_include'] is not None):\n",
    "    # Move to creation.\n",
    "    #if (preproc.featureset_encoders[0]['columns_exclude'] is not None):\n",
    "    #    raise ValueError(\"\\nYikes - Either `include_columns` or `exclude_columns` can be set, but not both.\\n\")    \n",
    "    include = preproc.featureset_encoders[0]['columns_include']\n",
    "    # Move to creation.\n",
    "    #if (not include):\n",
    "    #    raise ValueError(\"\\nYikes - Inclusion/ exclusion lists can be None, but cannot be empty e.g. `[]`.\\n\")\n",
    "    \n",
    "    # `in` must be an exact match when used at the list level.\n",
    "    # Partial matched like `\"saw\" in \"sawdust\"` don't trigger it.\n",
    "    subset_columns = [c for c in subset_columns if c in include]\n",
    "\n",
    "elif (preproc.featureset_encoders[0]['columns_exclude'] is not None):\n",
    "    # Move to creation.\n",
    "    #if (preproc.featureset_encoders[0]['columns_include'] is not None):\n",
    "    #    raise ValueError(\"\\nYikes - Either `include_columns` or `exclude_columns` can be set, but not both.\\n\")\n",
    "    exclude = preproc.featureset_encoders[0]['columns_exclude']\n",
    "    # Move to creation.\n",
    "    #if (not exclude):\n",
    "    #    raise ValueError(\"\\nYikes - Inclusion/ exclusion lists can be None, but cannot be empty e.g. `[]`.\\n\") \n",
    "    subset_columns = [c for c in subset_columns if c not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not subset_columns):\n",
    "    raise ValueError(\"\\nYikes - After applying `columns_include` and `columns_exclude`, there are no columns left to work with.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check columns against macro list. \n",
    "error if they are found.\n",
    "otherwise add them to the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df...selected_columns...straight to numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add to list of numpys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then prune original df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run next filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after all filters, combine the numpys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_details = preproc.featureset_encoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_encoder = subset_details['encoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df.select_dtypes(subset_details['include'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = subset.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_encoded_arr = subset_encoder.fit_transform(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_details_2 = preproc.featureset_encoder[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_encoder_2 = subset_details_2['encoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_2 = df.select_dtypes(subset_details_2['include'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols_2 = subset_2.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_encoded_arr_2 = subset_encoder_2.fit_transform(subset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12052239, -0.73266327],\n",
       "       [-1.28055041, -0.6812386 ],\n",
       "       [ 1.16002802,  1.41390187]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_encoded_arr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_encoded_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12052239, -0.73266327],\n",
       "       [-1.28055041, -0.6812386 ],\n",
       "       [ 1.16002802,  1.41390187]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_encoded_arr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.12052239, -0.73266327],\n",
       "       [ 1.        , -1.28055041, -0.6812386 ],\n",
       "       [ 2.        ,  1.16002802,  1.41390187]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((subset_encoded_arr, subset_encoded_arr_2), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in subset_cols:\n",
    "    encoded_cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in subset_cols_2:\n",
    "    encoded_cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mode', 'size', 'height']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should do this as often as possible to reduce memory?\n",
    "df = df[df.columns.difference(encoded_cols, sort=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(encoded_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>larry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name\n",
       "0    bob\n",
       "1    jim\n",
       "2  larry"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = examples.demo_file_to_pandas('iris.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dataset.to_numpy(columns=['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    if (encoder.sparse == True):  \n",
    "        encoder.sparse = False\n",
    "except:\n",
    "    pass\n",
    "\n",
    "encoder.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'sklearn.preprocessing._encoders' not in str(type(oher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'sklearn.preprocessing._encoders' not in str(type(oher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oher.fit(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = oher.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<150x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 150 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scipy.sparse.csr'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.__module__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'scipy.sparse.csr.csr_matrix' in str(type(arr)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((subset_encoded_arr, subset_encoded_arr_2), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.toarray()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordiner = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalEncoder()"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordiner.fit(df[['price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = ordiner.transform(df[['price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.],\n",
       "       [27.],\n",
       "       [39.],\n",
       "       [38.],\n",
       "       [41.],\n",
       "       [36.],\n",
       "       [29.],\n",
       "       [35.],\n",
       "       [12.],\n",
       "       [17.]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocs = [\n",
    "    Binarizer, FunctionTransformer, KBinsDiscretizer, \n",
    "    KernelCenterer, LabelBinarizer, LabelEncoder, \n",
    "    MultiLabelBinarizer, MinMaxScaler, Normalizer,\n",
    "    OneHotEncoder, OrdinalEncoder, PolynomialFeatures,\n",
    "    PowerTransformer, QuantileTransformer, RobustScaler,\n",
    "    StandardScaler, add_dummy_feature, binarize,\n",
    "    label_binarize, maxabs_scale, minmax_scale, \n",
    "    normalize, quantile_transform, robust_scale,\n",
    "    scale, power_transform\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nYikes - The sklearn.preprocessing method you provided does not have a `fit` method.\nPlease use one of the uppercase methods.\nFor example: use `RobustScaler` instead of `robust_scale`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-7e17fce5438b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxabs_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nYikes - The sklearn.preprocessing method you provided does not have a `fit` method.\\nPlease use one of the uppercase methods.\\nFor example: use `RobustScaler` instead of `robust_scale`.\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxabs_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \nYikes - The sklearn.preprocessing method you provided does not have a `fit` method.\nPlease use one of the uppercase methods.\nFor example: use `RobustScaler` instead of `robust_scale`.\n"
     ]
    }
   ],
   "source": [
    "if (not hasattr(maxabs_scale, 'fit')):    \n",
    "    raise ValueError(\"\\nYikes - The `sklearn.preprocessing` method you provided does not have a `fit` method.\\nPlease use one of the uppercase methods instead.\\nFor example: use `RobustScaler` instead of `robust_scale`.\\n\")\n",
    "elif (hasattr(maxabs_scale, 'fit')):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarizer\n",
      "FunctionTransformer\n",
      "KBinsDiscretizer\n",
      "KernelCenterer\n",
      "LabelBinarizer\n",
      "LabelEncoder\n",
      "MultiLabelBinarizer\n",
      "MinMaxScaler\n",
      "Normalizer\n",
      "OneHotEncoder\n",
      "OrdinalEncoder\n",
      "PolynomialFeatures\n",
      "PowerTransformer\n",
      "QuantileTransformer\n",
      "RobustScaler\n",
      "StandardScaler\n",
      "add_dummy_feature\n",
      "binarize\n",
      "label_binarize\n",
      "maxabs_scale\n",
      "minmax_scale\n",
      "normalize\n",
      "quantile_transform\n",
      "robust_scale\n",
      "scale\n",
      "power_transform\n"
     ]
    }
   ],
   "source": [
    "for p in preprocs:\n",
    "    print(\n",
    "        p.__name__\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Binarizer',\n",
       " 'FunctionTransformer',\n",
       " 'KBinsDiscretizer',\n",
       " 'KernelCenterer',\n",
       " 'LabelBinarizer',\n",
       " 'LabelEncoder',\n",
       " 'MaxAbsScaler',\n",
       " 'MinMaxScaler',\n",
       " 'MultiLabelBinarizer',\n",
       " 'Normalizer',\n",
       " 'OneHotEncoder',\n",
       " 'OrdinalEncoder',\n",
       " 'PolynomialFeatures',\n",
       " 'PowerTransformer',\n",
       " 'QuantileTransformer',\n",
       " 'RobustScaler',\n",
       " 'StandardScaler',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_csr_polynomial_expansion',\n",
       " '_data',\n",
       " '_discretization',\n",
       " '_encoders',\n",
       " '_function_transformer',\n",
       " '_label',\n",
       " 'add_dummy_feature',\n",
       " 'binarize',\n",
       " 'label_binarize',\n",
       " 'maxabs_scale',\n",
       " 'minmax_scale',\n",
       " 'normalize',\n",
       " 'power_transform',\n",
       " 'quantile_transform',\n",
       " 'robust_scale',\n",
       " 'scale']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(preprocz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as preprocz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Snarp:\n",
    "    garp:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "snarpper = Snarp()\n",
    "snarpper.garp=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "snarpper = Snarp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if (snarpper.garp==4):\n",
    "        print(\"yup\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "don't support `add_dummy_feature`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/Users/Layne/Desktop/aiqc/aiqc/data/dtype_testing.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doom_float64</th>\n",
       "      <th>radiance_float32</th>\n",
       "      <th>temperature_float</th>\n",
       "      <th>weekday_object</th>\n",
       "      <th>hour_object</th>\n",
       "      <th>moonday_int64</th>\n",
       "      <th>month_int32</th>\n",
       "      <th>color_uint8</th>\n",
       "      <th>shape_int</th>\n",
       "      <th>kingdom_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000.50</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sunday</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99793.11</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>monday</td>\n",
       "      <td>two</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99585.72</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>three</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99378.33</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>four</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99170.94</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>thursday</td>\n",
       "      <td>five</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kokiri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doom_float64  radiance_float32  temperature_float weekday_object  \\\n",
       "0     100000.50              -0.1                0.0         sunday   \n",
       "1      99793.11              -0.2                1.5         monday   \n",
       "2      99585.72              -0.3                3.0        tuesday   \n",
       "3      99378.33              -0.4                4.5      wednesday   \n",
       "4      99170.94              -0.5                6.0       thursday   \n",
       "\n",
       "  hour_object  moonday_int64  month_int32  color_uint8  shape_int  \\\n",
       "0         one              1            1            0          0   \n",
       "1         two              2            2            0          0   \n",
       "2       three              3            3            0          0   \n",
       "3        four              4            4            0          0   \n",
       "4        five              5            5            0          0   \n",
       "\n",
       "  kingdom_category  \n",
       "0           kokiri  \n",
       "1           kokiri  \n",
       "2           kokiri  \n",
       "3           kokiri  \n",
       "4           kokiri  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "List of methods where it's okay to `only_fit_train==False`:\n",
    "\n",
    "[Binarizer, FunctionTransformer, KBinsDiscretizer, LabelBinarizer, LabelEncoder, MultiLabelBinarizer, OneHotEncoder, OrdinalEncoder, PolynomialFeatures, QuantileTransformer] so long as \n",
    "`FunctionTransformer` doesn't rely on statistical information derived from the test set.\n",
    "`QuantileTransformer` applies either lowest or highest bin if test samples fall outside min/max bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "lzt_str = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_str = np.array(lzt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_str = d1_str.reshape(d1_str.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_str_multi = d1_str.reshape(int(d1_str.shape[0]/3), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "lzt_int = [1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_int = np.array(lzt_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_int = d1_int.reshape(d1_int.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_int_multi = d2_int.reshape(int(d2_int.shape[0]/3), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "lzt_int_neg = [-1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_int_neg = np.array(lzt_int_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_int_neg = d1_int_neg.reshape(d1_int_neg.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_int_neg_multi = d1_int_neg.reshape(int(d1_int_neg.shape[0]/3), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "lzt_flt = [0.1, 21.2, 39.3, 72.4, 0.5, 5.6, 0.7, 13.8, 103.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_flt = np.array(lzt_flt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_flt = d1_flt.reshape(d1_flt.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_flt_multi = d1_flt.reshape(int(d1_flt.shape[0]/3), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "lzt_flt_neg = [-0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_flt_neg = np.array(lzt_flt_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_flt_neg = d1_flt_neg.reshape(d1_flt_neg.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_flt_neg_multi = d1_flt_neg.reshape(int(d1_flt_neg.shape[0]/3), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataz = [d1_str, d2_str, d2_str_multi, d1_int, d2_int, d2_int_multi, d1_int_neg, d2_int_neg, d2_int_neg_multi, d1_flt, d2_flt, d2_flt_multi, d1_flt_neg, d2_flt_neg, d2_flt_neg_multi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderz = [Binarizer(), FunctionTransformer(), KBinsDiscretizer(), KernelCenterer(), LabelBinarizer(), LabelEncoder(), MultiLabelBinarizer(), MaxAbsScaler(), MinMaxScaler(), Normalizer(), OneHotEncoder(), OrdinalEncoder(), PolynomialFeatures(), PowerTransformer(), QuantileTransformer(), RobustScaler(), StandardScaler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "compatibility = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in encoderz:\n",
    "    compatibility[str(e)] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d1_str).shape)\n",
    "        print(encoder.fit_transform(d1_str).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d2_str).shape)\n",
    "        print(encoder.fit_transform(d2_str).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d2_str_multi).shape)\n",
    "        print(encoder.fit_transform(d2_str_multi).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d1_int).shape)\n",
    "        print(encoder.fit_transform(d1_int).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d2_int).shape)\n",
    "        print(encoder.fit_transform(d2_int).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d2_int_multi).shape)\n",
    "        print(encoder.fit_transform(d2_int_multi).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d1_int_neg).shape)\n",
    "        print(encoder.fit_transform(d1_int_neg).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d2_int_neg).shape)\n",
    "        print(encoder.fit_transform(d2_int_neg).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d2_int_neg_multi).shape)\n",
    "        print(encoder.fit_transform(d2_int_neg_multi).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d1_flt).shape)\n",
    "        print(encoder.fit_transform(d1_flt).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d2_flt).shape)\n",
    "        print(encoder.fit_transform(d2_flt).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d2_flt_multi).shape)\n",
    "        print(encoder.fit_transform(d2_flt_multi).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d1_flt_neg).shape)\n",
    "        print(encoder.fit_transform(d1_flt_neg).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d2_flt_neg).shape)\n",
    "        print(encoder.fit_transform(d2_flt_neg).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for encoder in encoderz:\n",
    "    try:\n",
    "        print(str(encoder))\n",
    "        print(encoder.fit_transform(d2_flt_neg_multi).shape)\n",
    "        print(encoder.fit_transform(d2_flt_neg_multi).dtype)\n",
    "    except:\n",
    "        print(\"failed   <----------\")\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(0)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        compatibility[str(encoder)].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "for k,v in compatibility.items():\n",
    "    print(len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\n",
    "    'str_1D',\n",
    "    'str_2D_1col',\n",
    "    'str_2D_3cols',\n",
    "    \n",
    "    'int_1D',\n",
    "    'int_2D_1col',\n",
    "    'int_2D_3cols',\n",
    "    \n",
    "    'int_negative_1D',\n",
    "    'int_negative_2D_1col',\n",
    "    'int_negative_2D_3cols',\n",
    "    \n",
    "    'float_1D',\n",
    "    'float_2D_1col',\n",
    "    'float_2D_3cols',\n",
    "    \n",
    "    'float_negative_1D',\n",
    "    'float_negative_2D_1col',\n",
    "    'float_negative_2D_3cols'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "compatibility_df = pd.DataFrame.from_records(compatibility).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_raw = compatibility_df.columns.to_list()\n",
    "cols_dct = dict(zip(cols_raw, col_names))\n",
    "\n",
    "compatibility_df = compatibility_df.rename(columns=cols_dct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['str_1D', 'str_2D_1col', 'str_2D_3cols', 'int_1D', 'int_2D_1col',\n",
       "       'int_2D_3cols', 'int_negative_1D', 'int_negative_2D_1col',\n",
       "       'int_negative_2D_3cols', 'float_1D', 'float_2D_1col', 'float_2D_3cols',\n",
       "       'float_negative_1D', 'float_negative_2D_1col',\n",
       "       'float_negative_2D_3cols'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compatibility_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>float_1D</th>\n",
       "      <th>float_2D_1col</th>\n",
       "      <th>float_2D_3cols</th>\n",
       "      <th>float_negative_1D</th>\n",
       "      <th>float_negative_2D_1col</th>\n",
       "      <th>float_negative_2D_3cols</th>\n",
       "      <th>int_1D</th>\n",
       "      <th>int_2D_1col</th>\n",
       "      <th>int_2D_3cols</th>\n",
       "      <th>int_negative_1D</th>\n",
       "      <th>int_negative_2D_1col</th>\n",
       "      <th>int_negative_2D_3cols</th>\n",
       "      <th>str_1D</th>\n",
       "      <th>str_2D_1col</th>\n",
       "      <th>str_2D_3cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Binarizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FunctionTransformer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBinsDiscretizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelCenterer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelBinarizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelEncoder()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxAbsScaler()</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinMaxScaler()</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiLabelBinarizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OneHotEncoder()</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrdinalEncoder()</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolynomialFeatures()</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PowerTransformer()</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileTransformer()</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RobustScaler()</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler()</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       float_1D  float_2D_1col  float_2D_3cols  \\\n",
       "Binarizer()                   0              1               1   \n",
       "FunctionTransformer()         1              1               1   \n",
       "KBinsDiscretizer()            0              1               1   \n",
       "KernelCenterer()              0              0               1   \n",
       "LabelBinarizer()              0              0               0   \n",
       "LabelEncoder()                1              1               0   \n",
       "MaxAbsScaler()                0              1               1   \n",
       "MinMaxScaler()                0              1               1   \n",
       "MultiLabelBinarizer()         0              1               1   \n",
       "Normalizer()                  0              1               1   \n",
       "OneHotEncoder()               0              1               1   \n",
       "OrdinalEncoder()              0              1               1   \n",
       "PolynomialFeatures()          0              1               1   \n",
       "PowerTransformer()            0              1               1   \n",
       "QuantileTransformer()         0              1               1   \n",
       "RobustScaler()                0              1               1   \n",
       "StandardScaler()              0              1               1   \n",
       "\n",
       "                       float_negative_1D  float_negative_2D_1col  \\\n",
       "Binarizer()                            0                       1   \n",
       "FunctionTransformer()                  1                       1   \n",
       "KBinsDiscretizer()                     0                       1   \n",
       "KernelCenterer()                       0                       0   \n",
       "LabelBinarizer()                       0                       0   \n",
       "LabelEncoder()                         1                       1   \n",
       "MaxAbsScaler()                         0                       1   \n",
       "MinMaxScaler()                         0                       1   \n",
       "MultiLabelBinarizer()                  0                       1   \n",
       "Normalizer()                           0                       1   \n",
       "OneHotEncoder()                        0                       1   \n",
       "OrdinalEncoder()                       0                       1   \n",
       "PolynomialFeatures()                   0                       1   \n",
       "PowerTransformer()                     0                       1   \n",
       "QuantileTransformer()                  0                       1   \n",
       "RobustScaler()                         0                       1   \n",
       "StandardScaler()                       0                       1   \n",
       "\n",
       "                       float_negative_2D_3cols  int_1D  int_2D_1col  \\\n",
       "Binarizer()                                  1       0            1   \n",
       "FunctionTransformer()                        1       1            1   \n",
       "KBinsDiscretizer()                           1       0            1   \n",
       "KernelCenterer()                             1       0            0   \n",
       "LabelBinarizer()                             0       1            1   \n",
       "LabelEncoder()                               0       1            1   \n",
       "MaxAbsScaler()                               1       0            1   \n",
       "MinMaxScaler()                               1       0            1   \n",
       "MultiLabelBinarizer()                        1       0            1   \n",
       "Normalizer()                                 1       0            1   \n",
       "OneHotEncoder()                              1       0            1   \n",
       "OrdinalEncoder()                             1       0            1   \n",
       "PolynomialFeatures()                         1       0            1   \n",
       "PowerTransformer()                           1       0            1   \n",
       "QuantileTransformer()                        1       0            1   \n",
       "RobustScaler()                               1       0            1   \n",
       "StandardScaler()                             1       0            1   \n",
       "\n",
       "                       int_2D_3cols  int_negative_1D  int_negative_2D_1col  \\\n",
       "Binarizer()                       1                0                     1   \n",
       "FunctionTransformer()             1                1                     1   \n",
       "KBinsDiscretizer()                1                0                     1   \n",
       "KernelCenterer()                  1                0                     0   \n",
       "LabelBinarizer()                  0                1                     1   \n",
       "LabelEncoder()                    0                1                     1   \n",
       "MaxAbsScaler()                    1                0                     1   \n",
       "MinMaxScaler()                    1                0                     1   \n",
       "MultiLabelBinarizer()             1                0                     1   \n",
       "Normalizer()                      1                0                     1   \n",
       "OneHotEncoder()                   1                0                     1   \n",
       "OrdinalEncoder()                  1                0                     1   \n",
       "PolynomialFeatures()              1                0                     1   \n",
       "PowerTransformer()                1                0                     1   \n",
       "QuantileTransformer()             1                0                     1   \n",
       "RobustScaler()                    1                0                     1   \n",
       "StandardScaler()                  1                0                     1   \n",
       "\n",
       "                       int_negative_2D_3cols  str_1D  str_2D_1col  \\\n",
       "Binarizer()                                1       0            0   \n",
       "FunctionTransformer()                      1       1            1   \n",
       "KBinsDiscretizer()                         1       0            0   \n",
       "KernelCenterer()                           1       0            0   \n",
       "LabelBinarizer()                           0       1            1   \n",
       "LabelEncoder()                             0       1            1   \n",
       "MaxAbsScaler()                             1       0            0   \n",
       "MinMaxScaler()                             1       0            0   \n",
       "MultiLabelBinarizer()                      1       1            1   \n",
       "Normalizer()                               1       0            0   \n",
       "OneHotEncoder()                            1       0            1   \n",
       "OrdinalEncoder()                           1       0            1   \n",
       "PolynomialFeatures()                       1       0            0   \n",
       "PowerTransformer()                         1       0            0   \n",
       "QuantileTransformer()                      1       0            0   \n",
       "RobustScaler()                             1       0            0   \n",
       "StandardScaler()                           1       0            0   \n",
       "\n",
       "                       str_2D_3cols  \n",
       "Binarizer()                       0  \n",
       "FunctionTransformer()             1  \n",
       "KBinsDiscretizer()                0  \n",
       "KernelCenterer()                  0  \n",
       "LabelBinarizer()                  0  \n",
       "LabelEncoder()                    0  \n",
       "MaxAbsScaler()                    0  \n",
       "MinMaxScaler()                    0  \n",
       "MultiLabelBinarizer()             1  \n",
       "Normalizer()                      0  \n",
       "OneHotEncoder()                   1  \n",
       "OrdinalEncoder()                  1  \n",
       "PolynomialFeatures()              0  \n",
       "PowerTransformer()                0  \n",
       "QuantileTransformer()             0  \n",
       "RobustScaler()                    0  \n",
       "StandardScaler()                  0  "
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples.encoder_compatibility_to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>float_1D</th>\n",
       "      <th>float_negative_1D</th>\n",
       "      <th>int_1D</th>\n",
       "      <th>int_negative_1D</th>\n",
       "      <th>str_1D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Binarizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FunctionTransformer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBinsDiscretizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelCenterer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelBinarizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelEncoder()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxAbsScaler()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinMaxScaler()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiLabelBinarizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OneHotEncoder()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrdinalEncoder()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolynomialFeatures()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PowerTransformer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileTransformer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RobustScaler()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       float_1D  float_negative_1D  int_1D  int_negative_1D  \\\n",
       "Binarizer()                   0                  0       0                0   \n",
       "FunctionTransformer()         1                  1       1                1   \n",
       "KBinsDiscretizer()            0                  0       0                0   \n",
       "KernelCenterer()              0                  0       0                0   \n",
       "LabelBinarizer()              0                  0       1                1   \n",
       "LabelEncoder()                1                  1       1                1   \n",
       "MaxAbsScaler()                0                  0       0                0   \n",
       "MinMaxScaler()                0                  0       0                0   \n",
       "MultiLabelBinarizer()         0                  0       0                0   \n",
       "Normalizer()                  0                  0       0                0   \n",
       "OneHotEncoder()               0                  0       0                0   \n",
       "OrdinalEncoder()              0                  0       0                0   \n",
       "PolynomialFeatures()          0                  0       0                0   \n",
       "PowerTransformer()            0                  0       0                0   \n",
       "QuantileTransformer()         0                  0       0                0   \n",
       "RobustScaler()                0                  0       0                0   \n",
       "StandardScaler()              0                  0       0                0   \n",
       "\n",
       "                       str_1D  \n",
       "Binarizer()                 0  \n",
       "FunctionTransformer()       1  \n",
       "KBinsDiscretizer()          0  \n",
       "KernelCenterer()            0  \n",
       "LabelBinarizer()            1  \n",
       "LabelEncoder()              1  \n",
       "MaxAbsScaler()              0  \n",
       "MinMaxScaler()              0  \n",
       "MultiLabelBinarizer()       1  \n",
       "Normalizer()                0  \n",
       "OneHotEncoder()             0  \n",
       "OrdinalEncoder()            0  \n",
       "PolynomialFeatures()        0  \n",
       "PowerTransformer()          0  \n",
       "QuantileTransformer()       0  \n",
       "RobustScaler()              0  \n",
       "StandardScaler()            0  "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples.encoder_compatibility_to_pandas()[['float_1D', 'float_negative_1D', 'int_1D', 'int_negative_1D', 'str_1D']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>float_1D</th>\n",
       "      <th>float_negative_1D</th>\n",
       "      <th>int_1D</th>\n",
       "      <th>int_negative_1D</th>\n",
       "      <th>str_1D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Binarizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FunctionTransformer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBinsDiscretizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelCenterer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelBinarizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelEncoder()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxAbsScaler()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinMaxScaler()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiLabelBinarizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OneHotEncoder()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrdinalEncoder()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolynomialFeatures()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PowerTransformer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileTransformer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RobustScaler()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       float_1D  float_negative_1D  int_1D  int_negative_1D  \\\n",
       "Binarizer()                   0                  0       0                0   \n",
       "FunctionTransformer()         1                  1       1                1   \n",
       "KBinsDiscretizer()            0                  0       0                0   \n",
       "KernelCenterer()              0                  0       0                0   \n",
       "LabelBinarizer()              0                  0       1                1   \n",
       "LabelEncoder()                1                  1       1                1   \n",
       "MaxAbsScaler()                0                  0       0                0   \n",
       "MinMaxScaler()                0                  0       0                0   \n",
       "MultiLabelBinarizer()         0                  0       0                0   \n",
       "Normalizer()                  0                  0       0                0   \n",
       "OneHotEncoder()               0                  0       0                0   \n",
       "OrdinalEncoder()              0                  0       0                0   \n",
       "PolynomialFeatures()          0                  0       0                0   \n",
       "PowerTransformer()            0                  0       0                0   \n",
       "QuantileTransformer()         0                  0       0                0   \n",
       "RobustScaler()                0                  0       0                0   \n",
       "StandardScaler()              0                  0       0                0   \n",
       "\n",
       "                       str_1D  \n",
       "Binarizer()                 0  \n",
       "FunctionTransformer()       1  \n",
       "KBinsDiscretizer()          0  \n",
       "KernelCenterer()            0  \n",
       "LabelBinarizer()            1  \n",
       "LabelEncoder()              1  \n",
       "MaxAbsScaler()              0  \n",
       "MinMaxScaler()              0  \n",
       "MultiLabelBinarizer()       1  \n",
       "Normalizer()                0  \n",
       "OneHotEncoder()             0  \n",
       "OrdinalEncoder()            0  \n",
       "PolynomialFeatures()        0  \n",
       "PowerTransformer()          0  \n",
       "QuantileTransformer()       0  \n",
       "RobustScaler()              0  \n",
       "StandardScaler()            0  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples.encoder_compatibility_to_pandas()[['float_1D', 'float_negative_1D', 'int_1D', 'int_negative_1D', 'str_1D']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>float_2D_1col</th>\n",
       "      <th>float_negative_2D_1col</th>\n",
       "      <th>int_2D_1col</th>\n",
       "      <th>int_negative_2D_1col</th>\n",
       "      <th>str_2D_1col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Binarizer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FunctionTransformer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBinsDiscretizer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelCenterer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelBinarizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelEncoder()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxAbsScaler()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinMaxScaler()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiLabelBinarizer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalizer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OneHotEncoder()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrdinalEncoder()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolynomialFeatures()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PowerTransformer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileTransformer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RobustScaler()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       float_2D_1col  float_negative_2D_1col  int_2D_1col  \\\n",
       "Binarizer()                        1                       1            1   \n",
       "FunctionTransformer()              1                       1            1   \n",
       "KBinsDiscretizer()                 1                       1            1   \n",
       "KernelCenterer()                   0                       0            0   \n",
       "LabelBinarizer()                   0                       0            1   \n",
       "LabelEncoder()                     1                       1            1   \n",
       "MaxAbsScaler()                     1                       1            1   \n",
       "MinMaxScaler()                     1                       1            1   \n",
       "MultiLabelBinarizer()              1                       1            1   \n",
       "Normalizer()                       1                       1            1   \n",
       "OneHotEncoder()                    1                       1            1   \n",
       "OrdinalEncoder()                   1                       1            1   \n",
       "PolynomialFeatures()               1                       1            1   \n",
       "PowerTransformer()                 1                       1            1   \n",
       "QuantileTransformer()              1                       1            1   \n",
       "RobustScaler()                     1                       1            1   \n",
       "StandardScaler()                   1                       1            1   \n",
       "\n",
       "                       int_negative_2D_1col  str_2D_1col  \n",
       "Binarizer()                               1            0  \n",
       "FunctionTransformer()                     1            1  \n",
       "KBinsDiscretizer()                        1            0  \n",
       "KernelCenterer()                          0            0  \n",
       "LabelBinarizer()                          1            1  \n",
       "LabelEncoder()                            1            1  \n",
       "MaxAbsScaler()                            1            0  \n",
       "MinMaxScaler()                            1            0  \n",
       "MultiLabelBinarizer()                     1            1  \n",
       "Normalizer()                              1            0  \n",
       "OneHotEncoder()                           1            1  \n",
       "OrdinalEncoder()                          1            1  \n",
       "PolynomialFeatures()                      1            0  \n",
       "PowerTransformer()                        1            0  \n",
       "QuantileTransformer()                     1            0  \n",
       "RobustScaler()                            1            0  \n",
       "StandardScaler()                          1            0  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples.encoder_compatibility_to_pandas()[['float_2D_1col', 'float_negative_2D_1col', 'int_2D_1col', 'int_negative_2D_1col', 'str_2D_1col']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>float_2D_3cols</th>\n",
       "      <th>float_negative_2D_3cols</th>\n",
       "      <th>int_2D_3cols</th>\n",
       "      <th>int_negative_2D_3cols</th>\n",
       "      <th>str_2D_3cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Binarizer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FunctionTransformer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBinsDiscretizer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelCenterer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelBinarizer()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelEncoder()</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxAbsScaler()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinMaxScaler()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiLabelBinarizer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalizer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OneHotEncoder()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrdinalEncoder()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolynomialFeatures()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PowerTransformer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileTransformer()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RobustScaler()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler()</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       float_2D_3cols  float_negative_2D_3cols  int_2D_3cols  \\\n",
       "Binarizer()                         1                        1             1   \n",
       "FunctionTransformer()               1                        1             1   \n",
       "KBinsDiscretizer()                  1                        1             1   \n",
       "KernelCenterer()                    1                        1             1   \n",
       "LabelBinarizer()                    0                        0             0   \n",
       "LabelEncoder()                      0                        0             0   \n",
       "MaxAbsScaler()                      1                        1             1   \n",
       "MinMaxScaler()                      1                        1             1   \n",
       "MultiLabelBinarizer()               1                        1             1   \n",
       "Normalizer()                        1                        1             1   \n",
       "OneHotEncoder()                     1                        1             1   \n",
       "OrdinalEncoder()                    1                        1             1   \n",
       "PolynomialFeatures()                1                        1             1   \n",
       "PowerTransformer()                  1                        1             1   \n",
       "QuantileTransformer()               1                        1             1   \n",
       "RobustScaler()                      1                        1             1   \n",
       "StandardScaler()                    1                        1             1   \n",
       "\n",
       "                       int_negative_2D_3cols  str_2D_3cols  \n",
       "Binarizer()                                1             0  \n",
       "FunctionTransformer()                      1             1  \n",
       "KBinsDiscretizer()                         1             0  \n",
       "KernelCenterer()                           1             0  \n",
       "LabelBinarizer()                           0             0  \n",
       "LabelEncoder()                             0             0  \n",
       "MaxAbsScaler()                             1             0  \n",
       "MinMaxScaler()                             1             0  \n",
       "MultiLabelBinarizer()                      1             1  \n",
       "Normalizer()                               1             0  \n",
       "OneHotEncoder()                            1             1  \n",
       "OrdinalEncoder()                           1             1  \n",
       "PolynomialFeatures()                       1             0  \n",
       "PowerTransformer()                         1             0  \n",
       "QuantileTransformer()                      1             0  \n",
       "RobustScaler()                             1             0  \n",
       "StandardScaler()                           1             0  "
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples.encoder_compatibility_to_pandas()[['float_2D_3cols', 'float_negative_2D_3cols', 'int_2D_3cols', 'int_negative_2D_3cols', 'str_2D_3cols']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_dataz = {\n",
    "    'd2_flt':d2_flt,\n",
    "    'd2_flt_multi': d2_flt_multi,\n",
    "    'd2_flt_neg':d2_flt_neg,\n",
    "    'd2_flt_neg_multi':d2_flt_neg_multi,\n",
    "    'd2_int':d2_int,\n",
    "    'd2_int_multi':d2_int_multi, \n",
    "    'd2_int_neg':d2_int_neg,\n",
    "    'd2_int_neg_multi':d2_int_neg_multi, \n",
    "    'd2_str':d2_str,\n",
    "    'd2_str_multi':d2_str_multi\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d2_str\n",
      "Binarizer()\n",
      "\n",
      "\n",
      "\n",
      "d2_str_multi\n",
      "Binarizer()\n",
      "\n",
      "\n",
      "\n",
      "d2_str\n",
      "KBinsDiscretizer()\n",
      "\n",
      "\n",
      "\n",
      "d2_str_multi\n",
      "KBinsDiscretizer()\n",
      "\n",
      "\n",
      "\n",
      "d2_flt\n",
      "KernelCenterer()\n",
      "\n",
      "\n",
      "\n",
      "d2_flt_neg\n",
      "KernelCenterer()\n",
      "\n",
      "\n",
      "\n",
      "d2_int\n",
      "KernelCenterer()\n",
      "\n",
      "\n",
      "\n",
      "d2_int_neg\n",
      "KernelCenterer()\n",
      "\n",
      "\n",
      "\n",
      "d2_str\n",
      "KernelCenterer()\n",
      "\n",
      "\n",
      "\n",
      "d2_str_multi\n",
      "KernelCenterer()\n",
      "\n",
      "\n",
      "\n",
      "d2_flt\n",
      "LabelBinarizer()\n",
      "\n",
      "\n",
      "\n",
      "d2_flt_multi\n",
      "LabelBinarizer()\n",
      "\n",
      "\n",
      "\n",
      "d2_flt_neg\n",
      "LabelBinarizer()\n",
      "\n",
      "\n",
      "\n",
      "d2_flt_neg_multi\n",
      "LabelBinarizer()\n",
      "\n",
      "\n",
      "\n",
      "d2_flt_multi\n",
      "LabelEncoder()\n",
      "\n",
      "\n",
      "\n",
      "d2_flt_neg_multi\n",
      "LabelEncoder()\n",
      "\n",
      "\n",
      "\n",
      "d2_int_multi\n",
      "LabelEncoder()\n",
      "\n",
      "\n",
      "\n",
      "d2_int_neg_multi\n",
      "LabelEncoder()\n",
      "\n",
      "\n",
      "\n",
      "d2_str_multi\n",
      "LabelEncoder()\n",
      "\n",
      "\n",
      "\n",
      "d2_str\n",
      "MaxAbsScaler()\n",
      "\n",
      "\n",
      "\n",
      "d2_str_multi\n",
      "MaxAbsScaler()\n",
      "\n",
      "\n",
      "\n",
      "d2_str\n",
      "MinMaxScaler()\n",
      "\n",
      "\n",
      "\n",
      "d2_str_multi\n",
      "MinMaxScaler()\n",
      "\n",
      "\n",
      "\n",
      "d2_str\n",
      "Normalizer()\n",
      "\n",
      "\n",
      "\n",
      "d2_str_multi\n",
      "Normalizer()\n",
      "\n",
      "\n",
      "\n",
      "d2_str\n",
      "PolynomialFeatures()\n",
      "\n",
      "\n",
      "\n",
      "d2_str_multi\n",
      "PolynomialFeatures()\n",
      "\n",
      "\n",
      "\n",
      "d2_str\n",
      "PowerTransformer()\n",
      "\n",
      "\n",
      "\n",
      "d2_str_multi\n",
      "PowerTransformer()\n",
      "\n",
      "\n",
      "\n",
      "d2_str\n",
      "QuantileTransformer()\n",
      "\n",
      "\n",
      "\n",
      "d2_str_multi\n",
      "QuantileTransformer()\n",
      "\n",
      "\n",
      "\n",
      "d2_str\n",
      "RobustScaler()\n",
      "\n",
      "\n",
      "\n",
      "d2_str_multi\n",
      "RobustScaler()\n",
      "\n",
      "\n",
      "\n",
      "d2_str\n",
      "StandardScaler()\n",
      "\n",
      "\n",
      "\n",
      "d2_str_multi\n",
      "StandardScaler()\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "failures = []\n",
    "successes = []\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    for e in encoderz:\n",
    "        for d_name, d in d2_dataz.items():\n",
    "            try:\n",
    "                # aiqc `to_numpy()` always fetches 2D.\n",
    "                e.fit_transform(d)\n",
    "            except:\n",
    "                # At this point, \"2D\" failed. It had 1 or more columns.\n",
    "                try:\n",
    "                    width = d.shape[1]\n",
    "                    if (width > 1):\n",
    "                        # Reshape \"2D many columns\" to “3D of 2D single columns.”\n",
    "                        d3 = d[None].T\n",
    "                    elif (width == 1):\n",
    "                        # Reshape \"2D single columns\" to “3D of 2D single columns”.\n",
    "                        d3 = d.reshape(1, d.shape[0], 1)    \n",
    "                    del d\n",
    "                    if (width > 1):\n",
    "                        # Fit against each 2D array within the 3D array.\n",
    "                        fits = {}\n",
    "                        for i, arr in enumerate(d3):\n",
    "                            fits[i] = e.fit(arr)\n",
    "                        # Transform each 2D array.\n",
    "                        # Transform output will not have same dimensionality so pack new array.\n",
    "                        output = []\n",
    "                        for i, arr in enumerate(d3):\n",
    "                            # Access the previous fits using column index `i`.\n",
    "                            fitted_preproc = fits[i]\n",
    "                            # Access and transform each column of the array. \n",
    "                            output.append(\n",
    "                                fitted_preproc.transform(d3[i])\n",
    "                            )\n",
    "                        output = np.array(output)\n",
    "                    elif (width == 1):\n",
    "                        # Skip because 2D single column already failed.\n",
    "                        pass\n",
    "                except:\n",
    "                    # At this point, \"2D single column\" has failed.\n",
    "                    # So reshape each \"2D into a 1D\" and then store those 1Ds in a 2D.\n",
    "                    try:\n",
    "                        # Reshape “3D of 2D single column” to “2D of 1D”\n",
    "                        d2 = d3.transpose(2,0,1)[0]\n",
    "                        del d3\n",
    "                        # Fit against each column in 2D array.\n",
    "                        fits = {}\n",
    "                        for i, arr in enumerate(d2):\n",
    "                            fits[i] = e.fit(arr)\n",
    "                        # Transform each column in the 2D array.\n",
    "                        # Transform output will not have same dimensionality so pack new array.\n",
    "                        output = []\n",
    "                        for i, arr in enumerate(d2):\n",
    "                            # Access the previous fits using column index `i`.\n",
    "                            fitted_preproc = fits[i]\n",
    "                            # Access and transform each column of the array.\n",
    "                            output.append(\n",
    "                                fitted_preproc.transform(d2[i])\n",
    "                            )\n",
    "                        del d2\n",
    "                        output = np.array(output)\n",
    "                    except:\n",
    "                        raise ValueError(\"\\nYikes - Encoder failed to fit the columns you filtered.\\nTried (`try`) NumPy ndarray dimensionalities of:\\n- all columns as 2D array multiple columns\\n- each column as 2D array\\n- each column as 1D array\\n\\nOne of the following may wrong:\\n- dtype incompatible with that encoder\\n- dirty data like NaNs\\n- very rare; invalid KernelCenterer shape\\n\\nReference the encoder compatibility matrix:\\n`from aiqc import examples; examples.encoder_compatibility_to_pandas()`\")\n",
    "                    else:\n",
    "                        dimensionality = \"1D\"\n",
    "                        # Need to combine outputs.\n",
    "                else:\n",
    "                    dimensionality = \"2D_singleColumn\"\n",
    "                    # Need to combine outputs.\n",
    "            else:\n",
    "                dimensionality = \"2D_multiColumn\"\n",
    "                # Need to combine outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_d = np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5]])"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_d.reshape(one_d.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarizer()\n",
      "d2_flt\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "Binarizer()\n",
      "d2_flt_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "Binarizer()\n",
      "d2_flt_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "Binarizer()\n",
      "d2_flt_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "Binarizer()\n",
      "d2_int\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "Binarizer()\n",
      "d2_int_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "Binarizer()\n",
      "d2_int_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "Binarizer()\n",
      "d2_int_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "Binarizer()\n",
      "d2_str\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "FunctionTransformer()\n",
      "d2_flt\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "FunctionTransformer()\n",
      "d2_flt_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "FunctionTransformer()\n",
      "d2_flt_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "FunctionTransformer()\n",
      "d2_flt_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "FunctionTransformer()\n",
      "d2_int\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "FunctionTransformer()\n",
      "d2_int_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "FunctionTransformer()\n",
      "d2_int_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "FunctionTransformer()\n",
      "d2_int_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "FunctionTransformer()\n",
      "d2_str\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "FunctionTransformer()\n",
      "d2_str_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "KBinsDiscretizer()\n",
      "d2_flt\n",
      "(9, 5)\n",
      "\n",
      "\n",
      "KBinsDiscretizer()\n",
      "d2_flt_multi\n",
      "(3, 15)\n",
      "\n",
      "\n",
      "KBinsDiscretizer()\n",
      "d2_flt_neg\n",
      "(9, 5)\n",
      "\n",
      "\n",
      "KBinsDiscretizer()\n",
      "d2_flt_neg_multi\n",
      "(3, 15)\n",
      "\n",
      "\n",
      "KBinsDiscretizer()\n",
      "d2_int\n",
      "(9, 5)\n",
      "\n",
      "\n",
      "KBinsDiscretizer()\n",
      "d2_int_multi\n",
      "(3, 15)\n",
      "\n",
      "\n",
      "KBinsDiscretizer()\n",
      "d2_int_neg\n",
      "(9, 5)\n",
      "\n",
      "\n",
      "KBinsDiscretizer()\n",
      "d2_int_neg_multi\n",
      "(3, 15)\n",
      "\n",
      "\n",
      "KBinsDiscretizer()\n",
      "d2_str\n",
      "(3, 15)\n",
      "\n",
      "\n",
      "KBinsDiscretizer()\n",
      "d2_str_multi\n",
      "(3, 15)\n",
      "\n",
      "\n",
      "KernelCenterer()\n",
      "d2_flt\n",
      "(3, 15)\n",
      "\n",
      "\n",
      "KernelCenterer()\n",
      "d2_flt_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "KernelCenterer()\n",
      "d2_flt_neg\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "KernelCenterer()\n",
      "d2_flt_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "KernelCenterer()\n",
      "d2_int\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "KernelCenterer()\n",
      "d2_int_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "KernelCenterer()\n",
      "d2_int_neg\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "KernelCenterer()\n",
      "d2_int_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "KernelCenterer()\n",
      "d2_str\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "KernelCenterer()\n",
      "d2_str_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "LabelBinarizer()\n",
      "d2_flt\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "LabelBinarizer()\n",
      "d2_flt_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "LabelBinarizer()\n",
      "d2_flt_neg\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "LabelBinarizer()\n",
      "d2_flt_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "LabelBinarizer()\n",
      "d2_int\n",
      "(9, 9)\n",
      "\n",
      "\n",
      "LabelBinarizer()\n",
      "d2_int_multi\n",
      "(3, 9)\n",
      "\n",
      "\n",
      "LabelBinarizer()\n",
      "d2_int_neg\n",
      "(9, 9)\n",
      "\n",
      "\n",
      "LabelBinarizer()\n",
      "d2_int_neg_multi\n",
      "(3, 9)\n",
      "\n",
      "\n",
      "LabelBinarizer()\n",
      "d2_str\n",
      "(9, 9)\n",
      "\n",
      "\n",
      "LabelBinarizer()\n",
      "d2_str_multi\n",
      "(3, 9)\n",
      "\n",
      "\n",
      "LabelEncoder()\n",
      "d2_flt\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "LabelEncoder()\n",
      "d2_flt_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "LabelEncoder()\n",
      "d2_int\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "LabelEncoder()\n",
      "d2_int_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "LabelEncoder()\n",
      "d2_str\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "MultiLabelBinarizer()\n",
      "d2_flt\n",
      "(9, 9)\n",
      "\n",
      "\n",
      "MultiLabelBinarizer()\n",
      "d2_flt_multi\n",
      "(3, 9)\n",
      "\n",
      "\n",
      "MultiLabelBinarizer()\n",
      "d2_flt_neg\n",
      "(9, 9)\n",
      "\n",
      "\n",
      "MultiLabelBinarizer()\n",
      "d2_flt_neg_multi\n",
      "(3, 9)\n",
      "\n",
      "\n",
      "MultiLabelBinarizer()\n",
      "d2_int\n",
      "(9, 9)\n",
      "\n",
      "\n",
      "MultiLabelBinarizer()\n",
      "d2_int_multi\n",
      "(3, 9)\n",
      "\n",
      "\n",
      "MultiLabelBinarizer()\n",
      "d2_int_neg\n",
      "(9, 9)\n",
      "\n",
      "\n",
      "MultiLabelBinarizer()\n",
      "d2_int_neg_multi\n",
      "(3, 9)\n",
      "\n",
      "\n",
      "MultiLabelBinarizer()\n",
      "d2_str\n",
      "(9, 9)\n",
      "\n",
      "\n",
      "MultiLabelBinarizer()\n",
      "d2_str_multi\n",
      "(3, 9)\n",
      "\n",
      "\n",
      "MaxAbsScaler()\n",
      "d2_flt\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "MaxAbsScaler()\n",
      "d2_flt_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "MaxAbsScaler()\n",
      "d2_flt_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "MaxAbsScaler()\n",
      "d2_flt_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "MaxAbsScaler()\n",
      "d2_int\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "MaxAbsScaler()\n",
      "d2_int_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "MaxAbsScaler()\n",
      "d2_int_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "MaxAbsScaler()\n",
      "d2_int_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "MaxAbsScaler()\n",
      "d2_str\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "MaxAbsScaler()\n",
      "d2_str_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "MinMaxScaler()\n",
      "d2_flt\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "MinMaxScaler()\n",
      "d2_flt_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "MinMaxScaler()\n",
      "d2_flt_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "MinMaxScaler()\n",
      "d2_flt_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "MinMaxScaler()\n",
      "d2_int\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "MinMaxScaler()\n",
      "d2_int_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "MinMaxScaler()\n",
      "d2_int_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "MinMaxScaler()\n",
      "d2_int_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "MinMaxScaler()\n",
      "d2_str\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "MinMaxScaler()\n",
      "d2_str_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "Normalizer()\n",
      "d2_flt\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "Normalizer()\n",
      "d2_flt_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "Normalizer()\n",
      "d2_flt_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "Normalizer()\n",
      "d2_flt_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "Normalizer()\n",
      "d2_int\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "Normalizer()\n",
      "d2_int_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "Normalizer()\n",
      "d2_int_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "Normalizer()\n",
      "d2_int_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "Normalizer()\n",
      "d2_str\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "OneHotEncoder()\n",
      "d2_flt\n",
      "(9, 9)\n",
      "\n",
      "\n",
      "OneHotEncoder()\n",
      "d2_flt_multi\n",
      "(3, 9)\n",
      "\n",
      "\n",
      "OneHotEncoder()\n",
      "d2_flt_neg\n",
      "(9, 9)\n",
      "\n",
      "\n",
      "OneHotEncoder()\n",
      "d2_flt_neg_multi\n",
      "(3, 9)\n",
      "\n",
      "\n",
      "OneHotEncoder()\n",
      "d2_int\n",
      "(9, 9)\n",
      "\n",
      "\n",
      "OneHotEncoder()\n",
      "d2_int_multi\n",
      "(3, 9)\n",
      "\n",
      "\n",
      "OneHotEncoder()\n",
      "d2_int_neg\n",
      "(9, 9)\n",
      "\n",
      "\n",
      "OneHotEncoder()\n",
      "d2_int_neg_multi\n",
      "(3, 9)\n",
      "\n",
      "\n",
      "OneHotEncoder()\n",
      "d2_str\n",
      "(9, 9)\n",
      "\n",
      "\n",
      "OneHotEncoder()\n",
      "d2_str_multi\n",
      "(3, 9)\n",
      "\n",
      "\n",
      "OrdinalEncoder()\n",
      "d2_flt\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "OrdinalEncoder()\n",
      "d2_flt_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "OrdinalEncoder()\n",
      "d2_flt_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "OrdinalEncoder()\n",
      "d2_flt_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "OrdinalEncoder()\n",
      "d2_int\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "OrdinalEncoder()\n",
      "d2_int_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "OrdinalEncoder()\n",
      "d2_int_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "OrdinalEncoder()\n",
      "d2_int_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "OrdinalEncoder()\n",
      "d2_str\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "OrdinalEncoder()\n",
      "d2_str_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "PolynomialFeatures()\n",
      "d2_flt\n",
      "(9, 3)\n",
      "\n",
      "\n",
      "PolynomialFeatures()\n",
      "d2_flt_multi\n",
      "(3, 10)\n",
      "\n",
      "\n",
      "PolynomialFeatures()\n",
      "d2_flt_neg\n",
      "(9, 3)\n",
      "\n",
      "\n",
      "PolynomialFeatures()\n",
      "d2_flt_neg_multi\n",
      "(3, 10)\n",
      "\n",
      "\n",
      "PolynomialFeatures()\n",
      "d2_int\n",
      "(9, 3)\n",
      "\n",
      "\n",
      "PolynomialFeatures()\n",
      "d2_int_multi\n",
      "(3, 10)\n",
      "\n",
      "\n",
      "PolynomialFeatures()\n",
      "d2_int_neg\n",
      "(9, 3)\n",
      "\n",
      "\n",
      "PolynomialFeatures()\n",
      "d2_int_neg_multi\n",
      "(3, 10)\n",
      "\n",
      "\n",
      "PolynomialFeatures()\n",
      "d2_str\n",
      "(3, 10)\n",
      "\n",
      "\n",
      "PowerTransformer()\n",
      "d2_flt\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "PowerTransformer()\n",
      "d2_flt_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "PowerTransformer()\n",
      "d2_flt_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "PowerTransformer()\n",
      "d2_flt_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "PowerTransformer()\n",
      "d2_int\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "PowerTransformer()\n",
      "d2_int_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "PowerTransformer()\n",
      "d2_int_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "PowerTransformer()\n",
      "d2_int_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "PowerTransformer()\n",
      "d2_str\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "PowerTransformer()\n",
      "d2_str_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "QuantileTransformer()\n",
      "d2_flt\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "QuantileTransformer()\n",
      "d2_flt_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "QuantileTransformer()\n",
      "d2_flt_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "QuantileTransformer()\n",
      "d2_flt_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "QuantileTransformer()\n",
      "d2_int\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "QuantileTransformer()\n",
      "d2_int_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "QuantileTransformer()\n",
      "d2_int_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "QuantileTransformer()\n",
      "d2_int_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "QuantileTransformer()\n",
      "d2_str\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "QuantileTransformer()\n",
      "d2_str_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "RobustScaler()\n",
      "d2_flt\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "RobustScaler()\n",
      "d2_flt_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "RobustScaler()\n",
      "d2_flt_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "RobustScaler()\n",
      "d2_flt_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "RobustScaler()\n",
      "d2_int\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "RobustScaler()\n",
      "d2_int_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "RobustScaler()\n",
      "d2_int_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "RobustScaler()\n",
      "d2_int_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "RobustScaler()\n",
      "d2_str\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "RobustScaler()\n",
      "d2_str_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "StandardScaler()\n",
      "d2_flt\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "StandardScaler()\n",
      "d2_flt_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "StandardScaler()\n",
      "d2_flt_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "StandardScaler()\n",
      "d2_flt_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "StandardScaler()\n",
      "d2_int\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "StandardScaler()\n",
      "d2_int_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "StandardScaler()\n",
      "d2_int_neg\n",
      "(9, 1)\n",
      "\n",
      "\n",
      "StandardScaler()\n",
      "d2_int_neg_multi\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "StandardScaler()\n",
      "d2_str\n",
      "(3, 3)\n",
      "\n",
      "\n",
      "StandardScaler()\n",
      "d2_str_multi\n",
      "(3, 3)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with warnings.catch_warnings(record=True) as w:\n",
    "#     for e in encoderz:\n",
    "#         for d_name, d in d2_dataz.items():\n",
    "#             try:\n",
    "#                 # aiqc `to_numpy()` always fetches 2D.\n",
    "#                 output = e.fit_transform(d)\n",
    "#             except:\n",
    "#                 # At this point, \"2D\" failed. It had 1 or more columns.\n",
    "#                 try:\n",
    "#                     width = d.shape[1]\n",
    "#                     if (width > 1):\n",
    "#                         # Reshape \"2D many columns\" to “3D of 2D single columns.”\n",
    "#                         d3 = d[None].T\n",
    "#                     elif (width == 1):\n",
    "#                         # Reshape \"2D single columns\" to “3D of 2D single columns”.\n",
    "#                         d3 = d.reshape(1, d.shape[0], 1)    \n",
    "#                     del d\n",
    "#                     if (width > 1):\n",
    "#                         # Fit against each 2D array within the 3D array.\n",
    "#                         fits = {}\n",
    "#                         for i, arr in enumerate(d3):\n",
    "#                             fits[i] = e.fit(arr)\n",
    "#                         # Transform each 2D array.\n",
    "#                         # Transform output will not have same dimensionality so pack new array.\n",
    "#                         output = []\n",
    "#                         for i, arr in enumerate(d3):\n",
    "#                             # Access the previous fits using column index `i`.\n",
    "#                             fitted_preproc = fits[i]\n",
    "#                             # Access and transform each column of the array. \n",
    "#                             output.append(\n",
    "#                                 fitted_preproc.transform(d3[i])\n",
    "#                             )\n",
    "#                         output = np.array(output)\n",
    "#                     elif (width == 1):\n",
    "#                         # Skip because 2D single column already failed.\n",
    "#                         pass\n",
    "#                 except:\n",
    "#                     # At this point, \"2D single column\" has failed.\n",
    "#                     # So reshape each \"2D into a 1D\" and then store those 1Ds in a 2D.\n",
    "#                     try:\n",
    "#                         # Reshape “3D of 2D single column” to “2D of 1D”\n",
    "#                         d2 = d3.transpose(2,0,1)[0]\n",
    "#                         del d3\n",
    "#                         # Fit against each column in 2D array.\n",
    "#                         fits = {}\n",
    "#                         for i, arr in enumerate(d2):\n",
    "#                             fits[i] = e.fit(arr)\n",
    "#                         # Transform each column in the 2D array.\n",
    "#                         # Transform output will not have same dimensionality so pack new array.\n",
    "#                         output = []\n",
    "#                         for i, arr in enumerate(d2):\n",
    "#                             # Access the previous fits using column index `i`.\n",
    "#                             fitted_preproc = fits[i]\n",
    "#                             # Access and transform each column of the array.\n",
    "#                             output.append(\n",
    "#                                 fitted_preproc.transform(d2[i])\n",
    "#                             )\n",
    "#                         del d2\n",
    "#                         output = np.array(output)\n",
    "#                     except:\n",
    "#                         pass\n",
    "#                         #raise ValueError(\"\\nYikes - Encoder failed to fit the columns you filtered.\\nTried (`try`) NumPy ndarray dimensionalities of:\\n- all columns as 2D array multiple columns\\n- each column as 2D array\\n- each column as 1D array\\n\\nOne of the following may wrong:\\n- dtype incompatible with that encoder\\n- dirty data like NaNs\\n- very rare; invalid KernelCenterer shape\\n\\nReference the encoder compatibility matrix:\\n`from aiqc import examples; examples.encoder_compatibility_to_pandas()`\")\n",
    "#                     else:\n",
    "#                         dimensionality = \"1D\"\n",
    "#                         #output = if_d3_wide_d2(output)  \n",
    "#                 else:\n",
    "#                     dimensionality = \"2D_singleColumn\"\n",
    "#                     #output = if_d3_wide_d2(output)\n",
    "#             else:\n",
    "#                 dimensionality = \"2D_multiColumn\"\n",
    "#                 #output = if_d3_wide_d2(output)\n",
    "            \n",
    "#             finally:\n",
    "#                 try:\n",
    "#                     output = if_d3_wide_d2(output)\n",
    "#                     output = if_d1_tall_d2(output)\n",
    "#                     print(str(e))\n",
    "#                     print(d_name)\n",
    "#                     print(output.shape)\n",
    "#                     print(\"\\n\")\n",
    "#                 except:\n",
    "#                     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dynamicDimension_fitTransform(sklearn_preprocess, sample_data):\n",
    "#     # Future: optimize to make sure not duplicating numpy. especially append to lists + reshape after transpose.\n",
    "#     with warnings.catch_warnings(record=True) as w:\n",
    "#         try:\n",
    "#             # aiqc `to_numpy()` always fetches 2D.\n",
    "#             encoded_samples = sklearn_preprocess.fit_transform(sample_data)\n",
    "#         except:\n",
    "#             # At this point, \"2D\" failed. It had 1 or more columns.\n",
    "#             try:\n",
    "#                 width = sample_data.shape[1]\n",
    "#                 if (width > 1):\n",
    "#                     # Reshape \"2D many columns\" to “3D of 2D single columns.”\n",
    "#                     d3 = sample_data[None].T\n",
    "#                 elif (width == 1):\n",
    "#                     # Reshape \"2D single columns\" to “3D of 2D single columns”.\n",
    "#                     d3 = sample_data.reshape(1, sample_data.shape[0], 1)    \n",
    "#                 del sample_data\n",
    "#                 if (width > 1):\n",
    "#                     # Fit against each 2D array within the 3D array.\n",
    "#                     fits = {}\n",
    "#                     for i, arr in enumerate(d3):\n",
    "#                         fits[i] = sklearn_preprocess.fit(arr)\n",
    "#                     # Transform each 2D array.\n",
    "#                     # Transform output will not have same dimensionality so pack new array.\n",
    "#                     encoded_samples = []\n",
    "#                     for i, arr in enumerate(d3):\n",
    "#                         # Access the previous fits using column index `i`.\n",
    "#                         fitted_preproc = fits[i]\n",
    "#                         # Access and transform each column of the array. \n",
    "#                         encoded_samples.append(\n",
    "#                             fitted_preproc.transform(d3[i])\n",
    "#                         )\n",
    "#                     encoded_samples = np.array(encoded_samples)\n",
    "#                 elif (width == 1):\n",
    "#                     # Skip because \"2D single column\" already failed.\n",
    "#                     pass\n",
    "#             except:\n",
    "#                 # At this point, \"2D single column\" has failed.\n",
    "#                 # So reshape each \"2D into a 1D\" and then store those 1Ds in a 2D.\n",
    "#                 try:\n",
    "#                     # Reshape “3D of 2D single column” to “2D of 1D”\n",
    "#                     d2 = d3.transpose(2,0,1)[0]\n",
    "#                     del d3\n",
    "#                     # Fit against each column in 2D array.\n",
    "#                     fits = {}\n",
    "#                     for i, arr in enumerate(d2):\n",
    "#                         fits[i] = sklearn_preprocess.fit(arr)\n",
    "#                     # Transform each column in the 2D array.\n",
    "#                     # Transform output will not have same dimensionality so pack new array.\n",
    "#                     encoded_samples = []\n",
    "#                     for i, arr in enumerate(d2):\n",
    "#                         # Access the previous fits using column index `i`.\n",
    "#                         fitted_preproc = fits[i]\n",
    "#                         # Access and transform each column of the array.\n",
    "#                         encoded_samples.append(\n",
    "#                             fitted_preproc.transform(d2[i])\n",
    "#                         )\n",
    "#                     del d2\n",
    "#                     encoded_samples = np.array(encoded_samples)\n",
    "#                 except:\n",
    "#                     raise ValueError(\"\\nYikes - Encoder failed to fit the columns you filtered.\\nTried (`try`) NumPy ndarray dimensionalities of:\\n- all columns as 2D array multiple columns\\n- each column as 2D array\\n- each column as 1D array\\n\\nOne of the following may wrong:\\n- dtype incompatible with that encoder\\n- dirty data like NaNs\\n- very rare; invalid KernelCenterer shape\\n\\nReference the encoder compatibility matrix:\\n`from aiqc import examples; examples.encoder_compatibility_to_pandas()`\")\n",
    "#                 else:\n",
    "#                     encoding_dimensionality = \"1D\"\n",
    "#             else:\n",
    "#                 encoding_dimensionality = \"2D_singleColumn\"\n",
    "#         else:\n",
    "#             encoding_dimensionality = \"2D_multiColumn\"\n",
    "#         finally:\n",
    "#             encoded_samples = if_d3_wide_d2(encoded_samples)\n",
    "#             encoded_samples = if_d1_tall_d2(encoded_samples)\n",
    "#             return encoded_samples, encoding_dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_dynamicDimensions(sklearn_preprocess:object, samples_to_fit:object):\n",
    "    fitted_encoders = {}\n",
    "    incompatibilities = {\n",
    "        \"strings\": [\n",
    "            \"KBinsDiscretizer\", \"KernelCenterer\", \"MaxAbsScaler\", \n",
    "            \"MinMaxScaler\", \"PowerTransformer\", \"QuantileTransformer\", \n",
    "            \"RobustScaler\", \"StandardScaler\"\n",
    "        ]\n",
    "        , \"floats\": \"LabelBinarizer\"\n",
    "        , \"numeric arrays without dimensions both odd and square. E.g. 3x3, 5x5\": \"KernelCenterer\"\n",
    "    }\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        try:\n",
    "            # aiqc `to_numpy()` always fetches 2D.\n",
    "            fitted_encoders[0] = sklearn_preprocess.fit(samples_to_fit)\n",
    "        except:\n",
    "            # At this point, \"2D\" failed. It had 1 or more columns.\n",
    "            try:\n",
    "                width = samples_to_fit.shape[1]\n",
    "                if (width > 1):\n",
    "                    # Reshape \"2D many columns\" to “3D of 2D single columns.”\n",
    "                    samples_to_fit = samples_to_fit[None].T                    \n",
    "                    # \"2D single column\" already failed. Need it to fail again to trigger except.\n",
    "                elif (width == 1):\n",
    "                    # Reshape \"2D single columns\" to “3D of 2D single columns.”\n",
    "                    samples_to_fit = samples_to_fit.reshape(1, samples_to_fit.shape[0], 1)    \n",
    "                # Fit against each 2D array within the 3D array.\n",
    "                for i, arr in enumerate(samples_to_fit):\n",
    "                    fitted_encoders[i] = sklearn_preprocess.fit(arr)\n",
    "            except:\n",
    "                # At this point, \"2D single column\" has failed.\n",
    "                try:\n",
    "                    # So reshape the \"3D of 2D_singleColumn\" into \"2D of 1D for each column.\"\n",
    "                    # This transformation is tested for both (width==1) as well as (width>1). \n",
    "                    samples_to_fit = samples_to_fit.transpose(2,0,1)[0]\n",
    "                    # Fit against each column in 2D array.\n",
    "                    for i, arr in enumerate(samples_to_fit):\n",
    "                        fitted_encoders[i] = sklearn_preprocess.fit(arr)\n",
    "                except:\n",
    "                    raise ValueError(f\"\\nYikes - Encoder failed to fit the columns you filtered.\\n\\nEither the data is dirty (e.g. contains NaNs), or an incompatible combination of data type and encoder was provided as seen below:\\n{incompatibilities}\")\n",
    "                else:\n",
    "                    encoding_dimension = \"1D\"\n",
    "            else:\n",
    "                encoding_dimension = \"2D_singleColumn\"\n",
    "        else:\n",
    "            encoding_dimension = \"2D_multiColumn\"\n",
    "    return fitted_encoders, encoding_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_1d_make_2d(array:object):\n",
    "    if (len(array.shape) == 1):\n",
    "        array = array.reshape(array.shape[0], 1)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dynamicDimensions(\n",
    "    fitted_encoders:dict\n",
    "    , encoding_dimension:str\n",
    "    , samples_to_transform:object\n",
    "):\n",
    "    #with warnings.catch_warnings(record=True) as w:\n",
    "    if (encoding_dimension == '2D_multiColumn'):\n",
    "        # Our `to_numpy` method fetches data as 2D. So it has 1+ columns. \n",
    "        encoded_samples = fitted_encoders[0].transform(samples_to_transform)\n",
    "        encoded_samples = if_1d_make_2d(array=encoded_samples)\n",
    "    elif (encoding_dimension == '2D_singleColumn'):\n",
    "        # Means that `2D_multiColumn` arrays cannot be used as is.\n",
    "        width = samples_to_transform.shape[1]\n",
    "        if (width == 1):\n",
    "            # It's already \"2D_singleColumn\"\n",
    "            encoded_samples = fitted_encoders[0].transform(samples_to_transform)\n",
    "            encoded_samples = if_1d_make_2d(array=encoded_samples)\n",
    "        elif (width > 1):\n",
    "            # Data must be fed into encoder as separate '2D_singleColumn' arrays, then recombined.\n",
    "            # Reshape \"2D many columns\" to “3D of 2D singleColumns” so we can loop on it.\n",
    "            encoded_samples = samples_to_transform[None].T\n",
    "            encoded_arrs = []\n",
    "            for i, arr in enumerate(encoded_samples):\n",
    "                encoded_arr = fitted_encoders[i].transform(arr)\n",
    "                encoded_arr = if_1d_make_2d(array=encoded_arr)  \n",
    "                encoded_arrs.append(encoded_arr)\n",
    "            encoded_samples = np.array(encoded_arrs).T\n",
    "            del encoded_arrs\n",
    "    elif (encoding_dimension == '1D'):\n",
    "        # From \"2D_multiColumn\" to \"2D with 1D for each column\"\n",
    "        # This `.T` works for both single and multi column.\n",
    "        encoded_samples = samples_to_transform.T\n",
    "        # Since each column is 1D, we care about rows now.\n",
    "        length = encoded_samples.shape[0]\n",
    "        if (length == 1):\n",
    "            encoded_samples = fitted_encoders[0].transform(encoded_samples)\n",
    "            # Some of these 1D encoders also output 1D.\n",
    "            # Need to put it back into 2D.\n",
    "            encoded_samples = if_1d_make_2d(array=encoded_samples)  \n",
    "        elif (length > 1):\n",
    "            encoded_arrs = []\n",
    "            for i, arr in enumerate(encoded_samples):\n",
    "                encoded_arr = fitted_encoders[i].transform(arr)\n",
    "                # Check if it is 1D before appending.\n",
    "                encoded_arr = if_1d_make_2d(array=encoded_arr)              \n",
    "                encoded_arrs.append(encoded_arr)\n",
    "            # From \"3D of 2D_singleColumn\" to \"2D_multiColumn\"\n",
    "            encoded_samples = np.array(encoded_arrs).T\n",
    "            del encoded_arrs\n",
    "    return encoded_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nYikes - Encoder failed to fit the columns you filtered.\n\nEither the data is dirty (e.g. contains NaNs), or an incompatible combination of data type and encoder was provided as seen below:\n{'strings': ['KBinsDiscretizer', 'KernelCenterer', 'MaxAbsScaler', 'MinMaxScaler', 'PowerTransformer', 'QuantileTransformer', 'RobustScaler', 'StandardScaler'], 'floats': 'LabelBinarizer', 'numeric arrays without dimensions both odd and square. E.g. 3x3, 5x5': 'KernelCenterer'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-979-dd0894e90f9d>\u001b[0m in \u001b[0;36mfit_dynamicDimensions\u001b[0;34m(sklearn_preprocess, samples_to_fit)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# aiqc `to_numpy()` always fetches 2D.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mfitted_encoders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn_preprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples_to_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mcol_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     33\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot perform reduce with flexible type",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-979-dd0894e90f9d>\u001b[0m in \u001b[0;36mfit_dynamicDimensions\u001b[0;34m(sklearn_preprocess, samples_to_fit)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples_to_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mfitted_encoders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn_preprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mcol_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     33\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot perform reduce with flexible type",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-979-dd0894e90f9d>\u001b[0m in \u001b[0;36mfit_dynamicDimensions\u001b[0;34m(sklearn_preprocess, samples_to_fit)\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples_to_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                         \u001b[0mfitted_encoders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn_preprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \"\"\"\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'numeric'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/jupyterlab/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-990-a9eef360cb7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             fitted_encoders, encoding_dimension = fit_dynamicDimensions(\n\u001b[1;32m      7\u001b[0m                 \u001b[0msklearn_preprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0;34m,\u001b[0m \u001b[0msamples_to_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-979-dd0894e90f9d>\u001b[0m in \u001b[0;36mfit_dynamicDimensions\u001b[0;34m(sklearn_preprocess, samples_to_fit)\u001b[0m\n\u001b[1;32m     38\u001b[0m                         \u001b[0mfitted_encoders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn_preprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nYikes - Encoder failed to fit the columns you filtered.\\n\\nEither the data is dirty (e.g. contains NaNs), or an incompatible combination of data type and encoder was provided as seen below:\\n{incompatibilities}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mencoding_dimension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \nYikes - Encoder failed to fit the columns you filtered.\n\nEither the data is dirty (e.g. contains NaNs), or an incompatible combination of data type and encoder was provided as seen below:\n{'strings': ['KBinsDiscretizer', 'KernelCenterer', 'MaxAbsScaler', 'MinMaxScaler', 'PowerTransformer', 'QuantileTransformer', 'RobustScaler', 'StandardScaler'], 'floats': 'LabelBinarizer', 'numeric arrays without dimensions both odd and square. E.g. 3x3, 5x5': 'KernelCenterer'}"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings(record=True) as w:\n",
    "    for e in encoderz:\n",
    "        for d_name, d in d2_dataz.items():\n",
    "\n",
    "            # Attempt to fit the encoder by reshaping/ transposing the data.\n",
    "            fitted_encoders, encoding_dimension = fit_dynamicDimensions(\n",
    "                sklearn_preprocess = e\n",
    "                , samples_to_fit = d\n",
    "            )\n",
    "\n",
    "            def if_1d_make_2d(array:object):\n",
    "                if (len(array.shape) == 1):\n",
    "                    array = array.reshape(array.shape[0], 1)\n",
    "                return array\n",
    "\n",
    "                encoded_samples = transform_dynamicDimensions(\n",
    "                    fitted_encoders = fitted_encoders\n",
    "                    , encoding_dimension = encoding_dimension\n",
    "                    , samples_to_transform = d\n",
    "                )            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_dataz = {\n",
    "    'd2_flt':d2_flt,\n",
    "    'd2_flt_multi': d2_flt_multi,\n",
    "    'd2_flt_neg':d2_flt_neg,\n",
    "    'd2_flt_neg_multi':d2_flt_neg_multi,\n",
    "    'd2_int':d2_int,\n",
    "    'd2_int_multi':d2_int_multi, \n",
    "    'd2_int_neg':d2_int_neg,\n",
    "    'd2_int_neg_multi':d2_int_neg_multi, \n",
    "    'd2_str':d2_str,\n",
    "    'd2_str_multi':d2_str_multi\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D_singleColumn\n",
      "{0: LabelBinarizer(), 1: LabelBinarizer(), 2: LabelBinarizer()}\n"
     ]
    }
   ],
   "source": [
    "en = LabelBinarizer()\n",
    "d = d2_int_multi\n",
    "\n",
    "fitted_encoders, encoding_dimension = fit_dynamicDimensions(\n",
    "    sklearn_preprocess = en\n",
    "    , samples_to_fit = d\n",
    ")\n",
    "\n",
    "print(encoding_dimension)\n",
    "print(fitted_encoders)\n",
    "        \n",
    "def if_1d_make_2d(array:object):\n",
    "    if (len(array.shape) == 1):\n",
    "        array = array.reshape(array.shape[0], 1)\n",
    "    return array\n",
    "\n",
    "encoded_samples = transform_dynamicDimensions(\n",
    "    fitted_encoders = fitted_encoders\n",
    "    , encoding_dimension = encoding_dimension\n",
    "    , samples_to_transform = d\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['a', 'b', 'c'],\n",
       "       ['d', 'e', 'f'],\n",
       "       ['g', 'h', 'i']], dtype='<U1')"
      ]
     },
     "execution_count": 983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2_str_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 984,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2_str_multi is np.string_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 987,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(d2_str_multi is '<U1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.str_"
      ]
     },
     "execution_count": 989,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d2_str_multi[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a == numpy.str_).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
